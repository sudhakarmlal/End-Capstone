{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Python_Code_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7913ee7803aa4bc6b412d79002d5c456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b8fe2b923de4c6aa7cdb31567efc41a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_804241072db94a14a16fc880029ff916",
              "IPY_MODEL_710aab86b70b4778b2ee1325a09195b3"
            ]
          }
        },
        "5b8fe2b923de4c6aa7cdb31567efc41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "804241072db94a14a16fc880029ff916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43449460796545f2b5939e7596b7bb9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f812852283f4d378142a9bc0047a569"
          }
        },
        "710aab86b70b4778b2ee1325a09195b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_298cc1d2afb6437899356e803b1f9179",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffe58b24e0e542cdbb5144855ba0a9ff"
          }
        },
        "43449460796545f2b5939e7596b7bb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f812852283f4d378142a9bc0047a569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "298cc1d2afb6437899356e803b1f9179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffe58b24e0e542cdbb5144855ba0a9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "462cf04aa1f84a14bfb4911dc05ae9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b5bf548430de48419682141ed00b52b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d5d28223a4534ea39bb6384ba3fc2419",
              "IPY_MODEL_42b0ecd5efa049b2ac680bd98b09a09e"
            ]
          }
        },
        "b5bf548430de48419682141ed00b52b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5d28223a4534ea39bb6384ba3fc2419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8e574edda3c24b77b30a0a847a81d86b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd4a18a4d3434b73a0ddbad2d7f0c5e5"
          }
        },
        "42b0ecd5efa049b2ac680bd98b09a09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42c2c7d188394b5bac2e81ccbc364b36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4727/4727 [00:43&lt;00:00, 108.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b84e32d24387454cad3c91737cbf2fc1"
          }
        },
        "8e574edda3c24b77b30a0a847a81d86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd4a18a4d3434b73a0ddbad2d7f0c5e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42c2c7d188394b5bac2e81ccbc364b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b84e32d24387454cad3c91737cbf2fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06979bf597194609ae454218df44aeca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af339821ae274399a6347f4ecfb273ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53dd8964dd3044cfa8ebb00cdb539fc0",
              "IPY_MODEL_5cec52b5593a4294a1564f35494ecdf2"
            ]
          }
        },
        "af339821ae274399a6347f4ecfb273ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53dd8964dd3044cfa8ebb00cdb539fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd1b72c6b33c4036a31d21d9474f673c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cef53d3d42104cdd820095c18beb2f4c"
          }
        },
        "5cec52b5593a4294a1564f35494ecdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c0813c8998434fb180c772ad87fbd895",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4727/4727 [00:37&lt;00:00, 126.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c61e0fbbd2f47bb8f7aaaced9dcefa4"
          }
        },
        "dd1b72c6b33c4036a31d21d9474f673c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cef53d3d42104cdd820095c18beb2f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0813c8998434fb180c772ad87fbd895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c61e0fbbd2f47bb8f7aaaced9dcefa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzxOJwN7EzFO"
      },
      "source": [
        "# Capstone Project- Transformer Based Model to generate  Python code\n",
        "\n",
        "The below notebook is about  sequence-to-sequence models using PyTorch and TorchText, we'll be implementing the model\n",
        "\n",
        "## Steps followed to generate Python Code\n",
        "\n",
        "### 1.Understanding Data\n",
        "The dataset contains **4600+** examples of English text to python code.The dataSet is of the following Format:\n",
        "\n",
        "#### a)  English Text:\n",
        "The English text describes what is the program all about.E.g\n",
        "\n",
        "      i) # write a program to find and print the smallest among three numbers\n",
        "      ii)# Write a program to check whether a number is prime or not\n",
        "      iii) # Write a program to find the factorial of a number\n",
        "     \n",
        "#### b)  Python code:\n",
        "The Python code corresponds to whatever described by the English Text  e.g \n",
        "\n",
        "Sample python function would look like\n",
        "    \n",
        "    def add_two_numbers(num1, num2):\n",
        "    sum = num1 + num2\n",
        "    return sum\n",
        "\n",
        "Sample python program would look like\n",
        "\n",
        "    num1 = 10\n",
        "    num2 = 12\n",
        "    num3 = 14\n",
        "    if (num1 >= num2) and (num1 >= num3):\n",
        "    largest = num1\n",
        "    elif (num2 >= num1) and (num2 >= num3):\n",
        "    largest = num2\n",
        "    else:\n",
        "      largest = num3\n",
        "    print(f'largest:{largest}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUmBJborJcau"
      },
      "source": [
        "## 2. Data Cleaning\n",
        "\n",
        "As a part of data preparation,data cleaning is pretty important.The cleaned data would later be preprocessed and fed to the transformer model. \n",
        "\n",
        "####  **Data Cleaning Strategy:**\n",
        "The DataCleaning procedure was **manual** for the following Strategy is followed for data cleaning\n",
        "\n",
        "    1.The complete Engilsh Text that describes the python code is kept in one line.\n",
        "    In case in some of the english texts in the dataset if it is in two lines it is brought to one line.\n",
        "\n",
        "    This has to be done to identify English text of the pair of English-Python to be fed to the transformer model \n",
        "\n",
        "    2.The python code is placed in the very next line.\n",
        "     For any of the python code if there is a space in between the\n",
        "    \"English text\" and the \"Python code\" the space is removed.\n",
        "    This space is removed.\n",
        "\n",
        "    Again this has to be done to identify the Python code of the pair of   \n",
        "    English-Python code to be fed to the transformer model\n",
        "\n",
        "    3.The in between spaces and comments in the python code has to be \n",
        "      removed so that the model doesn't learn any unncessary stuff e.g \n",
        "      redundant new lines or #comments(in between code)  for the python \n",
        "      code generated   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOnyfeDbXwdS"
      },
      "source": [
        "Special care was taken not to use mixed-use of tabs and spaces, or use of either 4 or 3 spaces, It was made sure that should be 4 spaces only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a_qt97UQlRR"
      },
      "source": [
        "## 3.Import Libraries\n",
        "\n",
        "We'll import PyTorch, TorchText, spaCy and a few standard modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAOn6GYN2cuQ",
        "outputId": "d6609cb7-f599-4ab5-e919-6f9b57c137d5"
      },
      "source": [
        "!pip install -U torch==1.7.0\n",
        "!pip install -U torchtext==0.8.1\n",
        "!pip install -U torchvision==0.8.0\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.6)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already up-to-date: torchtext==0.8.1 in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Collecting torch==1.7.1\n",
            "  Using cached https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchtext==0.8.1) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.8.0 has requirement torch==1.7.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.7.0\n",
            "    Uninstalling torch-1.7.0:\n",
            "      Successfully uninstalled torch-1.7.0\n",
            "Successfully installed torch-1.7.1\n",
            "Requirement already up-to-date: torchvision==0.8.0 in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.0) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.0) (1.19.5)\n",
            "Collecting torch==1.7.0\n",
            "  Using cached https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.0) (0.6)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.0) (3.7.4.3)\n",
            "\u001b[31mERROR: torchtext 0.8.1 has requirement torch==1.7.1, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.7.1\n",
            "    Uninstalling torch-1.7.1:\n",
            "      Successfully uninstalled torch-1.7.1\n",
            "Successfully installed torch-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUnMLdevEzFT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data import Field\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srzErHAsEzFU"
      },
      "source": [
        "Then set a random seed for deterministic results/reproducability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_wP4J4LEzFX"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMDAkUe2ZI9F"
      },
      "source": [
        "## 4.Data Preparation/Preprocessing\n",
        "\n",
        "The Data preprocessing would be required to generated pair of \"English-Python\" to be fed to the transformer model.Special Care is taken for the following:\n",
        "\n",
        "     1.All the python code in the generated pair out of the raw dataset\n",
        "      (of course cleaned with the steps mentioned above) is having proper indentations,spaces/tabs,new line characters .\n",
        "\n",
        "    2.Special care is taken to generate a workable python code by handling indentations,\",\" , \":\", tabs,new line characters.\n",
        "\n",
        "\n",
        "    3.Python tokenizer is used to generate tokens from the python code.\n",
        "    Note:Separate tokens are taken for the following:\n",
        "\n",
        "      a)COMMENT\n",
        "\n",
        "      b)ENCODING\n",
        "\n",
        "      c)INDENT\n",
        "\n",
        "      d)DEDENT\n",
        "\n",
        "      e)NEWLINE\n",
        "\n",
        "      f)ENDMARKER \n",
        "\n",
        "\n",
        "      The following code is used to consider the above as separate tokens while tokenizing python code into tokens\n",
        "\n",
        "      try:\n",
        "        tokens = tokenize.tokenize(io.BytesIO(text.encode('utf-8')).readline)\n",
        "        for five_tuple in tokens:\n",
        "            if five_tuple.type == tokenize.COMMENT:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.ENCODING:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.INDENT:\n",
        "                python_token_list.append(\"INDENT\")\n",
        "            elif five_tuple.type == tokenize.DEDENT:\n",
        "                python_token_list.append(\"DEDENT\")\n",
        "            elif five_tuple.type == tokenize.NL or five_tuple.type == tokenize.NEWLINE:\n",
        "                python_token_list.append(\"NEWLINE\")\n",
        "            elif five_tuple.type == tokenize.ENDMARKER :\n",
        "                continue\n",
        "            else:\n",
        "                python_token_list.append(five_tuple.string)\n",
        "    except Exception:\n",
        "        raised_exception = True\n",
        "\n",
        "\n",
        "      4.The spacy tokenizer is used to generate tokens for English text\n",
        "\n",
        "      5.The python tokenizer with special handling of the tokens (explained in Item3 above) is used to generate tokens out of the python \n",
        "      code.\n",
        "\n",
        "      6.A dataframe is formed out of The spacy tokens from English text and python tokens  from Python code.\n",
        "\n",
        "      7.The dataframe from Item6 above is used as an input to the model\n",
        "\n",
        "      8.Below is the sample python tokens  generated out of python tokenizer:\n",
        "\n",
        "      {'English': ['count', 'tuple', 'elements', 'inside', 'list'],\n",
        "      'Python': ['random',\n",
        "       '=',\n",
        "       '[',\n",
        "       \"'a'\",\n",
        "       ',',\n",
        "       '(',\n",
        "       \"'a'\",\n",
        "       ',',\n",
        "       \"'b'\",\n",
        "       ')',\n",
        "       ',',\n",
        "       '(',\n",
        "       \"'a'\",\n",
        "        ',',\n",
        "       \"'b'\",\n",
        "       ')',\n",
        "       ',',\n",
        "      '[',\n",
        "      '3',\n",
        "      ',',\n",
        "      '4',\n",
        "      ']',\n",
        "      ']',\n",
        "      'NEWLINE',\n",
        "      'count',\n",
        "      '=',\n",
        "     'random',\n",
        "      '.',\n",
        "     'count',\n",
        "     '(',\n",
        "     '(',\n",
        "     \"'a'\",\n",
        "     ',',\n",
        "     \"'b'\",\n",
        "     ')',\n",
        "     ')',\n",
        "     'NEWLINE',\n",
        "     'print',\n",
        "     '(',\n",
        "        '\"The count of (\\'a\\', \\'b\\') is:\"',\n",
        "      ',',\n",
        "      'count',\n",
        "     ')',\n",
        "      'NEWLINE']}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MUSMpThh376"
      },
      "source": [
        "## 5. Data Extension Strategy\n",
        "\n",
        "There is no special data extension strategy followed.Have used the same cleaned data ,did data preprocessing and converted them into pairs\n",
        "to feed to the transformer model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hawianoFEzFY"
      },
      "source": [
        "Instantiate English spaCy models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BP3YSvJEzFY",
        "outputId": "9ea15c48-8495-4366-f3a3-a250a095a92d"
      },
      "source": [
        "%%bash\n",
        "python -m spacy download en\n",
        "python -m spacy download de\n",
        "#spacy_de = spacy.load('de')\n",
        "#spacy_en = spacy.load('en')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py): started\n",
            "  Building wheel for de-core-news-sm (setup.py): finished with status 'done'\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=a9da96cdaf44f89038af627cadf97bfa6d4987dfc0e577114b2e1e5dabf4452e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0u00z7qd/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAq6OVJKfXm3"
      },
      "source": [
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bEkyPt5EzFY"
      },
      "source": [
        "For the English text spacy tokenizer is used.The below function takes \"English text\" as input and generate tokens using spacy tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KaGEZ45EzFZ"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh0VITKGYz6Z"
      },
      "source": [
        "## Read the dataset from the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM34DCqNURwX",
        "outputId": "b6a73465-988f-4124-d0bc-25c418166d67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTGgcuylUiKH",
        "outputId": "89ce9d0b-0aa6-4bd4-b4b9-ae2e0ef6a682"
      },
      "source": [
        "!ls '/content/gdrive/MyDrive/data'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cornell  cornell_movie_dialogs_corpus.zip  english-python.pt  python_data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V9qZho8UnAT"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-MHoWNwUtF0",
        "outputId": "509a9b6d-7aef-4e6f-c634-d48b1805ec08"
      },
      "source": [
        "corpus_name = \"data\"\n",
        "corpus = os.path.join(\"/content/gdrive/MyDrive\", corpus_name)\n",
        "\n",
        "def printLines(file, n=10):\n",
        "    print(file)\n",
        "    with open(file, 'rb') as datafile:\n",
        "        lines = datafile.readlines()\n",
        "    for line in lines[:n]:\n",
        "        print(line)\n",
        "\n",
        "printLines(os.path.join(corpus, \"python_data.txt\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/data/python_data.txt\n",
            "b'# write a python program to add two numbers \\r\\n'\n",
            "b'num1 = 1.5\\r\\n'\n",
            "b'num2 = 6.3\\r\\n'\n",
            "b'sum = num1 + num2\\r\\n'\n",
            "b\"print(f'Sum: {sum}')\\r\\n\"\n",
            "b'\\r\\n'\n",
            "b'# write a python function to add two user provided numbers and return the sum\\r\\n'\n",
            "b'def add_two_numbers(num1, num2):\\r\\n'\n",
            "b'    sum = num1 + num2\\r\\n'\n",
            "b'    return sum\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKXV-WgWNCx8"
      },
      "source": [
        "english_text_python_program_pair_list = []\n",
        "process_python_code=False\n",
        "i=1\n",
        "with open('/content/gdrive/MyDrive/data/python_data.txt', 'r', encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        #print(i)\n",
        "        i += 1\n",
        "        if process_python_code==False:\n",
        "            if line.strip() == '':\n",
        "                continue\n",
        "            if line.startswith('#'):\n",
        "                english_text = line\n",
        "                #english_text_list.append(line)\n",
        "                process_python_code=True\n",
        "                python_program=''\n",
        "            else:\n",
        "                print(i, \": \", line)            \n",
        "        else:\n",
        "            if line.strip() == '':\n",
        "                process_python_code=False\n",
        "                english_text_python_program_pair_list.append((english_text, python_program))\n",
        "                python_program=''\n",
        "                english_text =''\n",
        "            if line.lstrip().startswith('#'):\n",
        "                continue\n",
        "            else:\n",
        "                python_program += line"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls-5mZrkNfzN",
        "outputId": "d33cc55c-e756-427c-8ac3-c7a5180983e6"
      },
      "source": [
        "len(english_text_python_program_pair_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDwg8N3AxBM"
      },
      "source": [
        "english_text_list,python_program_list  = zip(*english_text_python_program_pair_list)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGQ_PNHLAydR"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'English': english_text_list, 'Python':python_program_list })"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "HSSq3thYA276",
        "outputId": "222e2caa-0860-4aee-fdba-4139f5fc10d3"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Python</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td># write a python program to add two numbers \\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td># write a python function to add two user prov...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td># write a program to find and print the larges...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td># write a program to find and print the smalle...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td># Write a python function to merge two given l...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td># Write a program to check whether a number is...</td>\n",
              "      <td>num = 337\\nif num &gt; 1:\\n   for i in range(2, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td># Write a python function that prints the fact...</td>\n",
              "      <td>def print_factors(x):\\n   print(f\"The factors ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td># Write a program to find the factorial of a n...</td>\n",
              "      <td>num = 13\\nfactorial = 1\\nif num &lt; 0:\\n   print...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td># Write a python function to print whether a n...</td>\n",
              "      <td>def check_pnz(num):\\n    if num &gt; 0:\\n       p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td># Write a program to print the multiplication ...</td>\n",
              "      <td>num = 9\\nfor i in range(1, 11):\\n   print(f\"{n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English                                             Python\n",
              "0     # write a python program to add two numbers \\n  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  # write a python function to add two user prov...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  # write a program to find and print the larges...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  # write a program to find and print the smalle...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  # Write a python function to merge two given l...     def merge_lists(l1, l2):\\n    return l1 + l2\\n\n",
              "5  # Write a program to check whether a number is...  num = 337\\nif num > 1:\\n   for i in range(2, n...\n",
              "6  # Write a python function that prints the fact...  def print_factors(x):\\n   print(f\"The factors ...\n",
              "7  # Write a program to find the factorial of a n...  num = 13\\nfactorial = 1\\nif num < 0:\\n   print...\n",
              "8  # Write a python function to print whether a n...  def check_pnz(num):\\n    if num > 0:\\n       p...\n",
              "9  # Write a program to print the multiplication ...  num = 9\\nfor i in range(1, 11):\\n   print(f\"{n..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qc0oQkmBa_-",
        "outputId": "6891560c-66b7-42b6-aad5-5208f4019992"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import random\n",
        "import random\n",
        "#import google_trans_new\n",
        "#from google_trans_new import google_translator\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "lem = WordNetLemmatizer()\n",
        "#translator = google_translator()\n",
        "\n",
        "def clean_text(text):\n",
        "    ## lower case\n",
        "    if not isinstance(text, str):\n",
        "      return str(text) \n",
        "    cleaned = text.lower()\n",
        "\n",
        "    urls_pattern = re.compile(r'https?://\\S+|www.\\S+')\n",
        "    cleaned = urls_pattern.sub(r'',cleaned)\n",
        "    \n",
        "    ## remove punctuations\n",
        "    punctuations = string.punctuation\n",
        "    cleaned_temp = \"\".join(character for character in cleaned if character not in punctuations)\n",
        "    \n",
        "    ## remove stopwords \n",
        "    words = cleaned_temp.split()\n",
        "    #stopword_lists = stopwords.words(\"english\")\n",
        "    #cleaned = [word for word in words if word not in stopword_lists]\n",
        "    cleaned = words\n",
        "    \n",
        "    ## normalization - lemmatization\n",
        "    #cleaned = [lem.lemmatize(word, \"v\") for word in cleaned]\n",
        "    #cleaned = [lem.lemmatize(word, \"n\") for word in cleaned]\n",
        "    \n",
        "    ## join \n",
        "    cleaned = \" \".join(cleaned)\n",
        "    return cleaned\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "7913ee7803aa4bc6b412d79002d5c456",
            "5b8fe2b923de4c6aa7cdb31567efc41a",
            "804241072db94a14a16fc880029ff916",
            "710aab86b70b4778b2ee1325a09195b3",
            "43449460796545f2b5939e7596b7bb9e",
            "4f812852283f4d378142a9bc0047a569",
            "298cc1d2afb6437899356e803b1f9179",
            "ffe58b24e0e542cdbb5144855ba0a9ff",
            "462cf04aa1f84a14bfb4911dc05ae9dd",
            "b5bf548430de48419682141ed00b52b3",
            "d5d28223a4534ea39bb6384ba3fc2419",
            "42b0ecd5efa049b2ac680bd98b09a09e",
            "8e574edda3c24b77b30a0a847a81d86b",
            "fd4a18a4d3434b73a0ddbad2d7f0c5e5",
            "42c2c7d188394b5bac2e81ccbc364b36",
            "b84e32d24387454cad3c91737cbf2fc1"
          ]
        },
        "id": "LJnuVpb-BTFG",
        "outputId": "71dc4ca3-ca92-41b5-f94f-2e1027532c70"
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "tqdm().pandas() \n",
        "\n",
        "df['English'] = df['English'].progress_apply(lambda txt: clean_text(txt))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7913ee7803aa4bc6b412d79002d5c456",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "462cf04aa1f84a14bfb4911dc05ae9dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4727.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "06979bf597194609ae454218df44aeca",
            "af339821ae274399a6347f4ecfb273ec",
            "53dd8964dd3044cfa8ebb00cdb539fc0",
            "5cec52b5593a4294a1564f35494ecdf2",
            "dd1b72c6b33c4036a31d21d9474f673c",
            "cef53d3d42104cdd820095c18beb2f4c",
            "c0813c8998434fb180c772ad87fbd895",
            "2c61e0fbbd2f47bb8f7aaaced9dcefa4"
          ]
        },
        "id": "4tvulIotBvPZ",
        "outputId": "23236a41-0c87-4ee2-d215-c3d77d121577"
      },
      "source": [
        "df['Python'] = df['Python'].progress_apply(lambda txt: txt.lstrip())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06979bf597194609ae454218df44aeca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4727.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "JKEeJH2qCA_t",
        "outputId": "6bd8f035-9514-45dc-f4a0-b5570f649696"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Python</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>write a program to check whether a number is p...</td>\n",
              "      <td>num = 337\\nif num &gt; 1:\\n   for i in range(2, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>write a python function that prints the factor...</td>\n",
              "      <td>def print_factors(x):\\n   print(f\"The factors ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>write a program to find the factorial of a number</td>\n",
              "      <td>num = 13\\nfactorial = 1\\nif num &lt; 0:\\n   print...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>write a python function to print whether a num...</td>\n",
              "      <td>def check_pnz(num):\\n    if num &gt; 0:\\n       p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>write a program to print the multiplication ta...</td>\n",
              "      <td>num = 9\\nfor i in range(1, 11):\\n   print(f\"{n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English                                             Python\n",
              "0          write a python program to add two numbers  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  write a program to find and print the largest ...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  write a program to find and print the smallest...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  write a python function to merge two given lis...     def merge_lists(l1, l2):\\n    return l1 + l2\\n\n",
              "5  write a program to check whether a number is p...  num = 337\\nif num > 1:\\n   for i in range(2, n...\n",
              "6  write a python function that prints the factor...  def print_factors(x):\\n   print(f\"The factors ...\n",
              "7  write a program to find the factorial of a number  num = 13\\nfactorial = 1\\nif num < 0:\\n   print...\n",
              "8  write a python function to print whether a num...  def check_pnz(num):\\n    if num > 0:\\n       p...\n",
              "9  write a program to print the multiplication ta...  num = 9\\nfor i in range(1, 11):\\n   print(f\"{n..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBDXgbNxvbdo"
      },
      "source": [
        "import tokenize\n",
        "import io\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_python(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Python Code to list of strings\n",
        "    \"\"\"\n",
        "    python_token_list = []\n",
        "    raised_exception = False\n",
        "    try:\n",
        "        tokens = tokenize.tokenize(io.BytesIO(text.encode('utf-8')).readline)\n",
        "        for five_tuple in tokens:\n",
        "            if five_tuple.type == tokenize.COMMENT:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.ENCODING:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.INDENT:\n",
        "                python_token_list.append(\"INDENT\")\n",
        "            elif five_tuple.type == tokenize.DEDENT:\n",
        "                python_token_list.append(\"DEDENT\")\n",
        "            elif five_tuple.type == tokenize.NL or five_tuple.type == tokenize.NEWLINE:\n",
        "                python_token_list.append(\"NEWLINE\")\n",
        "            elif five_tuple.type == tokenize.ENDMARKER :\n",
        "                continue\n",
        "            else:\n",
        "                python_token_list.append(five_tuple.string)\n",
        "    except Exception:\n",
        "        raised_exception = True\n",
        "        #print( \"Exception: \", Exception, \" program: \", text)\n",
        "    return python_token_list"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1U6dt9CHpSS",
        "outputId": "552ecd63-639d-4485-9aea-61783a326054"
      },
      "source": [
        "SRC = Field(tokenize=tokenize_en, \n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>',            \n",
        "            batch_first = True, \n",
        "            lower=True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_python, \n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>', \n",
        "            batch_first = True\n",
        "            )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Cq9YpFCF14"
      },
      "source": [
        "fields = [('English', SRC),('Python',TRG)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNpkuJq7HoUg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, valid = train_test_split(df, test_size=0.02)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jES070ThIBNq"
      },
      "source": [
        "train = train.reset_index(drop=True) ## This is being done because data.Example.fromlist was failing\n",
        "valid = valid.reset_index(drop=True) ## This is being done because data.Example.fromlist was failing"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1ueu0PaIEma"
      },
      "source": [
        "MAX_OUTPUT_SEQ_LENGTH = 100"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvn85iFZIUzt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qtkkMweIKY9",
        "outputId": "4a4288cb-5764-4e0d-df4b-3cee2a4f7c1a"
      },
      "source": [
        "example_trng = [Example.fromlist([train.English[i],train.Python[i]], fields) for i in range(train.shape[0]) if len(tokenize_python(train.Python[i])) <= MAX_OUTPUT_SEQ_LENGTH - 4 ] \n",
        "example_val = [Example.fromlist([valid.English[i],valid.Python[i]], fields) for i in range(valid.shape[0]) if len(tokenize_python(valid.Python[i])) <= MAX_OUTPUT_SEQ_LENGTH - 4 ] "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXAK2LlqIdsl"
      },
      "source": [
        "train_dataset = Dataset(example_trng, fields)\n",
        "valid_dataset = Dataset(example_val, fields)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKgtTU38Io2s",
        "outputId": "8a9b610c-e159-4516-a5da-918e4f8448f7"
      },
      "source": [
        "vars(train_dataset.examples[10])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'English': ['define',\n",
              "  'a',\n",
              "  'function',\n",
              "  'which',\n",
              "  'can',\n",
              "  'print',\n",
              "  'a',\n",
              "  'dictionary',\n",
              "  'where',\n",
              "  'the',\n",
              "  'keys',\n",
              "  'are',\n",
              "  'numbers',\n",
              "  'between',\n",
              "  '1',\n",
              "  'and',\n",
              "  '3',\n",
              "  'both',\n",
              "  'included',\n",
              "  'and',\n",
              "  'the',\n",
              "  'values',\n",
              "  'are',\n",
              "  'square',\n",
              "  'of',\n",
              "  'keys'],\n",
              " 'Python': ['def',\n",
              "  'print_dict_keys_val_1',\n",
              "  '(',\n",
              "  ')',\n",
              "  ':',\n",
              "  'NEWLINE',\n",
              "  'INDENT',\n",
              "  'd',\n",
              "  '=',\n",
              "  'dict',\n",
              "  '(',\n",
              "  ')',\n",
              "  'NEWLINE',\n",
              "  'd',\n",
              "  '[',\n",
              "  '1',\n",
              "  ']',\n",
              "  '=',\n",
              "  '1',\n",
              "  'NEWLINE',\n",
              "  'd',\n",
              "  '[',\n",
              "  '2',\n",
              "  ']',\n",
              "  '=',\n",
              "  '2',\n",
              "  '**',\n",
              "  '2',\n",
              "  'NEWLINE',\n",
              "  'd',\n",
              "  '[',\n",
              "  '3',\n",
              "  ']',\n",
              "  '=',\n",
              "  '3',\n",
              "  '**',\n",
              "  '2',\n",
              "  'NEWLINE',\n",
              "  'print',\n",
              "  '(',\n",
              "  'd',\n",
              "  ')',\n",
              "  'NEWLINE',\n",
              "  'DEDENT']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGNIQV0-Ir_3",
        "outputId": "3cbd07c8-2e1f-4853-c38d-ff4f25239886"
      },
      "source": [
        "vars(valid_dataset.examples[10])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'English': ['count', 'tuple', 'elements', 'inside', 'list'],\n",
              " 'Python': ['random',\n",
              "  '=',\n",
              "  '[',\n",
              "  \"'a'\",\n",
              "  ',',\n",
              "  '(',\n",
              "  \"'a'\",\n",
              "  ',',\n",
              "  \"'b'\",\n",
              "  ')',\n",
              "  ',',\n",
              "  '(',\n",
              "  \"'a'\",\n",
              "  ',',\n",
              "  \"'b'\",\n",
              "  ')',\n",
              "  ',',\n",
              "  '[',\n",
              "  '3',\n",
              "  ',',\n",
              "  '4',\n",
              "  ']',\n",
              "  ']',\n",
              "  'NEWLINE',\n",
              "  'count',\n",
              "  '=',\n",
              "  'random',\n",
              "  '.',\n",
              "  'count',\n",
              "  '(',\n",
              "  '(',\n",
              "  \"'a'\",\n",
              "  ',',\n",
              "  \"'b'\",\n",
              "  ')',\n",
              "  ')',\n",
              "  'NEWLINE',\n",
              "  'print',\n",
              "  '(',\n",
              "  '\"The count of (\\'a\\', \\'b\\') is:\"',\n",
              "  ',',\n",
              "  'count',\n",
              "  ')',\n",
              "  'NEWLINE']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUd2-nQ6I220"
      },
      "source": [
        "SRC.build_vocab(train_dataset)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJI4EpB1I4NG"
      },
      "source": [
        "TRG.build_vocab(train_dataset)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dmsx1WvEtwE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fhx__qZF3Hx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Y7dJieF7CI",
        "outputId": "c4284299-9cca-4124-9eab-7cd0dfb243fc"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_dataset, valid_dataset), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x:len(x.English),\n",
        "    sort_within_batch = False, \n",
        "    device = device)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcuPfeokiQt8"
      },
      "source": [
        "## 6. Model Architecture\n",
        "\n",
        "\n",
        "The Model used is **transformers with self-attention, multi-head, and scaled-dot product attention**\n",
        "\n",
        "The model is implemented from [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078). This model will achieve improved test perplexity whilst only using a single layer RNN in both the encoder and the decoder.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The general encoder-decoder model.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq1.png?raw=1)\n",
        "\n",
        "We use our encoder (green) over the embedded source sequence (yellow) to create a context vector (red). We then use that context vector with the decoder (blue) and a linear layer (purple) to generate the target sentence.\n",
        "\n",
        "the older models, we used an multi-layered LSTM as the encoder and decoder.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq4.png?raw=1)\n",
        "\n",
        "One downside of the previous model is that the decoder is trying to cram lots of information into the hidden states. Whilst decoding, the hidden state will need to contain information about the whole of the source sequence, as well as all of the tokens have been decoded so far. By alleviating some of this information compression, we can create a better model!\n",
        "\n",
        "We'll also be using a GRU (Gated Recurrent Unit) instead of an LSTM (Long Short-Term Memory). Why? Mainly because that's what they did in the paper (this paper also introduced GRUs) and also because we used LSTMs last time. To understand how GRUs (and LSTMs) differ from standard RNNS, check out [this](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) link. Is a GRU better than an LSTM? [Research](https://arxiv.org/abs/1412.3555) has shown they're pretty much the same, and both are better than standard RNNs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-symyN1zV-_q"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jarF42K0WNOX"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqJrb9iLWUHK"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqfGHRX9WZZf"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv8nGIYIWHgY"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVmuR1X_Wgi4"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIjpYdO4Wm7s"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVnrgIhbWtaG"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yESIrDzr0mNi",
        "outputId": "baf20868-f653-443e-ddc0-248b1b2f55c2"
      },
      "source": [
        "print(OUTPUT_DIM)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpPZIpK2-5x",
        "outputId": "30f4f160-9c78-4430-c403-45e04e09316c"
      },
      "source": [
        "print(INPUT_DIM)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0KBqQ2BWxuk"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsZC-bHkW3CT",
        "outputId": "3de954b6-2b32-4437-b7f3-5d3de3441b75"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 6,968,535 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3koKqh6GW7m4"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKj7voEHXArd"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juEcz_WrXFeY"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnrl6DgqXJet"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5HKu_FFXOQp"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.English\n",
        "        trg = batch.Python\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        print(trg.shape)\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6xj2J-tXT8B"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.English\n",
        "            trg = batch.Python\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            SRC.build_vocab(train_dataset)\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0idGzciCXae0"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJiU-8agXet8",
        "outputId": "50304a0a-a843-479a-9242-de38dfb4ac6b"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 01 | Time: 0m 5s\n",
            "\tTrain Loss: 5.882 | Train PPL: 358.607\n",
            "\t Val. Loss: 4.221 |  Val. PPL:  68.102\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 85])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 02 | Time: 0m 5s\n",
            "\tTrain Loss: 3.692 | Train PPL:  40.119\n",
            "\t Val. Loss: 3.031 |  Val. PPL:  20.718\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 03 | Time: 0m 5s\n",
            "\tTrain Loss: 2.877 | Train PPL:  17.756\n",
            "\t Val. Loss: 2.533 |  Val. PPL:  12.594\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 96])\n",
            "Epoch: 04 | Time: 0m 5s\n",
            "\tTrain Loss: 2.460 | Train PPL:  11.703\n",
            "\t Val. Loss: 2.211 |  Val. PPL:   9.125\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 05 | Time: 0m 5s\n",
            "\tTrain Loss: 2.153 | Train PPL:   8.613\n",
            "\t Val. Loss: 1.954 |  Val. PPL:   7.059\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 06 | Time: 0m 5s\n",
            "\tTrain Loss: 1.905 | Train PPL:   6.721\n",
            "\t Val. Loss: 1.766 |  Val. PPL:   5.847\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 07 | Time: 0m 5s\n",
            "\tTrain Loss: 1.695 | Train PPL:   5.448\n",
            "\t Val. Loss: 1.610 |  Val. PPL:   5.004\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([53, 89])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 08 | Time: 0m 5s\n",
            "\tTrain Loss: 1.521 | Train PPL:   4.578\n",
            "\t Val. Loss: 1.463 |  Val. PPL:   4.317\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 90])\n",
            "Epoch: 09 | Time: 0m 5s\n",
            "\tTrain Loss: 1.361 | Train PPL:   3.901\n",
            "\t Val. Loss: 1.356 |  Val. PPL:   3.879\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 92])\n",
            "Epoch: 10 | Time: 0m 5s\n",
            "\tTrain Loss: 1.228 | Train PPL:   3.413\n",
            "\t Val. Loss: 1.271 |  Val. PPL:   3.564\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 84])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 11 | Time: 0m 5s\n",
            "\tTrain Loss: 1.100 | Train PPL:   3.005\n",
            "\t Val. Loss: 1.198 |  Val. PPL:   3.313\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 85])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 12 | Time: 0m 5s\n",
            "\tTrain Loss: 0.995 | Train PPL:   2.706\n",
            "\t Val. Loss: 1.138 |  Val. PPL:   3.120\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 13 | Time: 0m 5s\n",
            "\tTrain Loss: 0.904 | Train PPL:   2.469\n",
            "\t Val. Loss: 1.081 |  Val. PPL:   2.947\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 14 | Time: 0m 5s\n",
            "\tTrain Loss: 0.809 | Train PPL:   2.246\n",
            "\t Val. Loss: 1.041 |  Val. PPL:   2.831\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 15 | Time: 0m 6s\n",
            "\tTrain Loss: 0.736 | Train PPL:   2.087\n",
            "\t Val. Loss: 0.990 |  Val. PPL:   2.691\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 16 | Time: 0m 6s\n",
            "\tTrain Loss: 0.670 | Train PPL:   1.955\n",
            "\t Val. Loss: 0.957 |  Val. PPL:   2.604\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 92])\n",
            "Epoch: 17 | Time: 0m 6s\n",
            "\tTrain Loss: 0.617 | Train PPL:   1.854\n",
            "\t Val. Loss: 0.929 |  Val. PPL:   2.533\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 18 | Time: 0m 6s\n",
            "\tTrain Loss: 0.564 | Train PPL:   1.757\n",
            "\t Val. Loss: 0.916 |  Val. PPL:   2.499\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([53, 82])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 19 | Time: 0m 6s\n",
            "\tTrain Loss: 0.518 | Train PPL:   1.679\n",
            "\t Val. Loss: 0.893 |  Val. PPL:   2.442\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 20 | Time: 0m 6s\n",
            "\tTrain Loss: 0.473 | Train PPL:   1.604\n",
            "\t Val. Loss: 0.874 |  Val. PPL:   2.397\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 95])\n",
            "Epoch: 21 | Time: 0m 6s\n",
            "\tTrain Loss: 0.435 | Train PPL:   1.546\n",
            "\t Val. Loss: 0.865 |  Val. PPL:   2.376\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 22 | Time: 0m 6s\n",
            "\tTrain Loss: 0.402 | Train PPL:   1.495\n",
            "\t Val. Loss: 0.851 |  Val. PPL:   2.341\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 23 | Time: 0m 6s\n",
            "\tTrain Loss: 0.372 | Train PPL:   1.450\n",
            "\t Val. Loss: 0.845 |  Val. PPL:   2.327\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 24 | Time: 0m 6s\n",
            "\tTrain Loss: 0.350 | Train PPL:   1.419\n",
            "\t Val. Loss: 0.829 |  Val. PPL:   2.290\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 83])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 25 | Time: 0m 6s\n",
            "\tTrain Loss: 0.325 | Train PPL:   1.385\n",
            "\t Val. Loss: 0.829 |  Val. PPL:   2.291\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 26 | Time: 0m 6s\n",
            "\tTrain Loss: 0.302 | Train PPL:   1.352\n",
            "\t Val. Loss: 0.815 |  Val. PPL:   2.260\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([53, 87])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 27 | Time: 0m 6s\n",
            "\tTrain Loss: 0.284 | Train PPL:   1.329\n",
            "\t Val. Loss: 0.813 |  Val. PPL:   2.254\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 28 | Time: 0m 6s\n",
            "\tTrain Loss: 0.263 | Train PPL:   1.301\n",
            "\t Val. Loss: 0.812 |  Val. PPL:   2.252\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 86])\n",
            "torch.Size([53, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 29 | Time: 0m 6s\n",
            "\tTrain Loss: 0.251 | Train PPL:   1.286\n",
            "\t Val. Loss: 0.798 |  Val. PPL:   2.221\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 30 | Time: 0m 6s\n",
            "\tTrain Loss: 0.236 | Train PPL:   1.266\n",
            "\t Val. Loss: 0.791 |  Val. PPL:   2.206\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 86])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 31 | Time: 0m 6s\n",
            "\tTrain Loss: 0.223 | Train PPL:   1.250\n",
            "\t Val. Loss: 0.790 |  Val. PPL:   2.203\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([53, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 32 | Time: 0m 6s\n",
            "\tTrain Loss: 0.210 | Train PPL:   1.234\n",
            "\t Val. Loss: 0.789 |  Val. PPL:   2.202\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 33 | Time: 0m 6s\n",
            "\tTrain Loss: 0.203 | Train PPL:   1.225\n",
            "\t Val. Loss: 0.804 |  Val. PPL:   2.235\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 34 | Time: 0m 6s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 0.795 |  Val. PPL:   2.215\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 95])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 35 | Time: 0m 6s\n",
            "\tTrain Loss: 0.178 | Train PPL:   1.194\n",
            "\t Val. Loss: 0.810 |  Val. PPL:   2.248\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 36 | Time: 0m 6s\n",
            "\tTrain Loss: 0.172 | Train PPL:   1.188\n",
            "\t Val. Loss: 0.796 |  Val. PPL:   2.216\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 37 | Time: 0m 6s\n",
            "\tTrain Loss: 0.164 | Train PPL:   1.178\n",
            "\t Val. Loss: 0.807 |  Val. PPL:   2.241\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 94])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 38 | Time: 0m 6s\n",
            "\tTrain Loss: 0.156 | Train PPL:   1.169\n",
            "\t Val. Loss: 0.810 |  Val. PPL:   2.247\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 82])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 39 | Time: 0m 6s\n",
            "\tTrain Loss: 0.149 | Train PPL:   1.161\n",
            "\t Val. Loss: 0.814 |  Val. PPL:   2.258\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 93])\n",
            "Epoch: 40 | Time: 0m 6s\n",
            "\tTrain Loss: 0.143 | Train PPL:   1.153\n",
            "\t Val. Loss: 0.820 |  Val. PPL:   2.269\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([53, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 41 | Time: 0m 6s\n",
            "\tTrain Loss: 0.140 | Train PPL:   1.150\n",
            "\t Val. Loss: 0.836 |  Val. PPL:   2.308\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 90])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 42 | Time: 0m 6s\n",
            "\tTrain Loss: 0.132 | Train PPL:   1.141\n",
            "\t Val. Loss: 0.830 |  Val. PPL:   2.294\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 89])\n",
            "Epoch: 43 | Time: 0m 6s\n",
            "\tTrain Loss: 0.128 | Train PPL:   1.137\n",
            "\t Val. Loss: 0.825 |  Val. PPL:   2.281\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 44 | Time: 0m 6s\n",
            "\tTrain Loss: 0.124 | Train PPL:   1.132\n",
            "\t Val. Loss: 0.820 |  Val. PPL:   2.271\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([53, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 45 | Time: 0m 6s\n",
            "\tTrain Loss: 0.123 | Train PPL:   1.131\n",
            "\t Val. Loss: 0.818 |  Val. PPL:   2.266\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 86])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 84])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 46 | Time: 0m 6s\n",
            "\tTrain Loss: 0.116 | Train PPL:   1.123\n",
            "\t Val. Loss: 0.837 |  Val. PPL:   2.309\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 47 | Time: 0m 6s\n",
            "\tTrain Loss: 0.114 | Train PPL:   1.121\n",
            "\t Val. Loss: 0.825 |  Val. PPL:   2.281\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 48 | Time: 0m 6s\n",
            "\tTrain Loss: 0.110 | Train PPL:   1.117\n",
            "\t Val. Loss: 0.830 |  Val. PPL:   2.294\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([53, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 49 | Time: 0m 6s\n",
            "\tTrain Loss: 0.105 | Train PPL:   1.111\n",
            "\t Val. Loss: 0.824 |  Val. PPL:   2.279\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([53, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 50 | Time: 0m 6s\n",
            "\tTrain Loss: 0.101 | Train PPL:   1.106\n",
            "\t Val. Loss: 0.841 |  Val. PPL:   2.319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBwOM7zilXFM"
      },
      "source": [
        "## 7. Evaluation Metric\n",
        "The model is used to acheive the perplexity.The perplexity is used as the evaluation metric.\n",
        "\n",
        "We acheived a test perplexity of **2.202**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yTEeDuReBLK",
        "outputId": "865e1d09-a84e-4ab0-923a-736f08490f76"
      },
      "source": [
        "model.load_state_dict(torch.load('tut6-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 0.789 | Test PPL:   2.202 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8C93617myYj"
      },
      "source": [
        "## 8.Model Prediction\n",
        "\n",
        "Now that the transformer model is trained.We would be using the model to predict the python code generated in case an \"English Text\" is given as input to the Model\n",
        "\n",
        "Also the python code generated is in the form of tokens.This has to further formatted to generate appropriate python code.\n",
        "\n",
        "\n",
        "A python intepreter has to be used to run the generated python code to verify if its working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLufM2mGeOtp"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqa7KbWyeme4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d216c274-cc0d-4e7c-c860-236660e5144a"
      },
      "source": [
        "example_idx = 8\n",
        "\n",
        "src = vars(train_dataset.examples[example_idx])['English']\n",
        "trg = vars(train_dataset.examples[example_idx])['Python']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['generate', 'a', 'python', 'list', 'of', 'all', 'the', 'even', 'numbers', 'between', 'two', 'given', 'numbers']\n",
            "trg = ['num1', '=', '4', 'NEWLINE', 'num2', '=', '30', 'NEWLINE', 'myval', '=', '[', 'i', 'for', 'i', 'in', 'range', '(', 'num1', ',', 'num2', ',', '2', ')', ']', 'NEWLINE', 'print', '(', 'myval', ')', 'NEWLINE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8lVDbmXfQfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2454332-0886-4e56-ef87-2221354cec50"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['num1', '=', '4', 'NEWLINE', 'num2', '=', '30', 'NEWLINE', 'myval', '=', '[', 'i', 'for', 'i', 'in', 'range', '(', 'num1', ',', 'num2', ',', '2', ')', ']', 'NEWLINE', 'print', '(', 'myval', ')', 'NEWLINE', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlpVqymUgHLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f77a699-9535-4b14-c902-47ff61832aaf"
      },
      "source": [
        "example_idx = 0\n",
        "\n",
        "src = vars(train_dataset.examples[example_idx])['English']\n",
        "trg = vars(train_dataset.examples[example_idx])['Python']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'function', 'to', 'accept', 'input', 'as', 'feet', 'and', 'inches', 'into', 'centimeters']\n",
            "trg = ['def', 'height_into_cms', '(', 'feet', ',', 'inches', ')', ':', 'NEWLINE', 'INDENT', 'ininches', '=', 'feet', '*', '12', '+', 'inches', 'NEWLINE', 'return', 'ininches', '*', '2.54', 'NEWLINE', 'DEDENT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcgS8xRAgMOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432c42d9-3194-405c-cbc3-eb37b98a46f8"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['def', 'height_into_cms', '(', 'feet', ',', 'inches', ')', ':', 'NEWLINE', 'INDENT', 'ininches', '=', 'feet', '*', '12', '+', 'inches', 'NEWLINE', 'return', 'ininches', '*', '2.54', 'NEWLINE', 'DEDENT', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzDVF1L_zyEq"
      },
      "source": [
        "list_test = ['def', 'height_into_cms', '(', 'feet', ',', 'inches', ')', ':', 'NEWLINE', 'INDENT', 'ininches', '=', 'feet', '*', '12', '+', 'inches', 'NEWLINE', 'return', 'ininches', '*', '2.54', 'NEWLINE', 'DEDENT']"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEPf0sn_0CGb",
        "outputId": "c61bb25c-ad98-422b-a817-7e3bf7adec30"
      },
      "source": [
        "str = \"\".join(list_test)\n",
        "print(str)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defheight_into_cms(feet,inches):NEWLINEINDENTininches=feet*12+inchesNEWLINEreturnininches*2.54NEWLINEDEDENT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sjfFv850afU"
      },
      "source": [
        "#list_test2 = ['def', 'height_into_cms', '(', 'feet', ',', 'inches', ')', ':', 'NEWLINE', 'INDENT', 'ininches', '=', 'feet', '*', '12', '+', 'inches', 'NEWLINE', 'return', 'ininches', '*', '2.54', 'NEWLINE', 'DEDENT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KimiZMUl0oSr"
      },
      "source": [
        "list_test2=['num1', '=', '4', 'NEWLINE', 'num2', '=', '30', 'NEWLINE', 'myval', '=', '[', 'i', 'for', 'i', 'in', 'range', '(', 'num1', ',', 'num2', ',', '2', ')', ']', 'NEWLINE', 'print', '(', 'myval', ')', 'NEWLINE', '<eos>']"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDFTCprS0trg",
        "outputId": "16332975-3da8-450b-cf07-c0a6935ddfa1"
      },
      "source": [
        "str2 = \"\".join(list_test2)\n",
        "print(str2)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num1=4NEWLINEnum2=30NEWLINEmyval=[iforiinrange(num1,num2,2)]NEWLINEprint(myval)NEWLINE<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY7SsC8TEzFn"
      },
      "source": [
        "Just looking at the test loss, we get better performance. This is a pretty good sign that this model architecture is doing something right! Relieving the information compression seems like the way forard, and in the next tutorial we'll expand on this even further with *attention*."
      ]
    }
  ]
}