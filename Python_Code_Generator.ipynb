{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Python_Code_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbdd95c2dcae43f89ac74474be00b030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d83603331089493a99c2200ed1647215",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b424d51652d947a7b6d4cb1ea86ae11c",
              "IPY_MODEL_dba9536503674dac8367fd4bc787cbea"
            ]
          }
        },
        "d83603331089493a99c2200ed1647215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b424d51652d947a7b6d4cb1ea86ae11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28291f2a401b4984ae7c6715199ffba6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8082f895449b4f58b24b740d41e30ce7"
          }
        },
        "dba9536503674dac8367fd4bc787cbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5704953bab524cbcbbc7a4b10a60beff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_556042bf6472476caf820b9d1e1d5acd"
          }
        },
        "28291f2a401b4984ae7c6715199ffba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8082f895449b4f58b24b740d41e30ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5704953bab524cbcbbc7a4b10a60beff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "556042bf6472476caf820b9d1e1d5acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a78511c0cf3b448198e1f22e72f461f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9c7219c2d6a4754a06e5463cea94217",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ae7ccdf6ad14b3b9a1478998484a577",
              "IPY_MODEL_bc14d0f349d34b8597084bde9dce7325"
            ]
          }
        },
        "a9c7219c2d6a4754a06e5463cea94217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ae7ccdf6ad14b3b9a1478998484a577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_815cd491991745d0bf63085c34fb20c0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8214a830426a4d3db866270f266df229"
          }
        },
        "bc14d0f349d34b8597084bde9dce7325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f41d0d886e94ffb98d0b540b8ce4259",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4727/4727 [00:05&lt;00:00, 841.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d4b26d7cf5b4f3d9efb863946074a3a"
          }
        },
        "815cd491991745d0bf63085c34fb20c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8214a830426a4d3db866270f266df229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f41d0d886e94ffb98d0b540b8ce4259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d4b26d7cf5b4f3d9efb863946074a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b391c5646d648cba8bec1ffbd3d4ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d976269dffc49c4a8507c402cbecc4a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ebd72e2a6f9246e0b1458834caa0a5fb",
              "IPY_MODEL_ea0aeb75bbb3442cb45851258003ff41"
            ]
          }
        },
        "2d976269dffc49c4a8507c402cbecc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebd72e2a6f9246e0b1458834caa0a5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_754a70a0d9664fd08dd5ee3cf9d2099f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db6c0bd6756644f08126ca3e2c7e205d"
          }
        },
        "ea0aeb75bbb3442cb45851258003ff41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae98e7b7ede34dfa812cce7ac3efae5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4727/4727 [00:28&lt;00:00, 164.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcdb672db9674cb88ee322407d2c520c"
          }
        },
        "754a70a0d9664fd08dd5ee3cf9d2099f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db6c0bd6756644f08126ca3e2c7e205d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae98e7b7ede34dfa812cce7ac3efae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcdb672db9674cb88ee322407d2c520c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzxOJwN7EzFO"
      },
      "source": [
        "# Capstone Project- Transformer Based Model to generate  Python code\n",
        "\n",
        "The below notebook is about  sequence-to-sequence models using PyTorch and TorchText, we'll be implementing the model\n",
        "\n",
        "## Steps followed to generate Python Code\n",
        "\n",
        "### 1.Understanding Data\n",
        "The dataset contains **4600+** examples of English text to python code.The dataSet is of the following Format:\n",
        "\n",
        "#### a)  English Text:\n",
        "The English text describes what is the program all about.E.g\n",
        "\n",
        "      i) # write a program to find and print the smallest among three numbers\n",
        "      ii)# Write a program to check whether a number is prime or not\n",
        "      iii) # Write a program to find the factorial of a number\n",
        "     \n",
        "#### b)  Python code:\n",
        "The Python code corresponds to whatever described by the English Text  e.g \n",
        "\n",
        "Sample python function would look like\n",
        "    \n",
        "    def add_two_numbers(num1, num2):\n",
        "    sum = num1 + num2\n",
        "    return sum\n",
        "\n",
        "Sample python program would look like\n",
        "\n",
        "    num1 = 10\n",
        "    num2 = 12\n",
        "    num3 = 14\n",
        "    if (num1 >= num2) and (num1 >= num3):\n",
        "    largest = num1\n",
        "    elif (num2 >= num1) and (num2 >= num3):\n",
        "    largest = num2\n",
        "    else:\n",
        "      largest = num3\n",
        "    print(f'largest:{largest}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUmBJborJcau"
      },
      "source": [
        "## 2. Data Cleaning\n",
        "\n",
        "As a part of data preparation,data cleaning is pretty important.The cleaned data would later be preprocessed and fed to the transformer model. \n",
        "\n",
        "####  **Data Cleaning Strategy:**\n",
        "The DataCleaning procedure was **manual** for the following Strategy is followed for data cleaning\n",
        "\n",
        "    1.The complete Engilsh Text that describes the python code is kept in one line.\n",
        "    In case in some of the english texts in the dataset if it is in two lines it is brought to one line.\n",
        "\n",
        "    This has to be done to identify English text of the pair of English-Python to be fed to the transformer model \n",
        "\n",
        "    2.The python code is placed in the very next line.\n",
        "     For any of the python code if there is a space in between the\n",
        "    \"English text\" and the \"Python code\" the space is removed.\n",
        "    This space is removed.\n",
        "\n",
        "    Again this has to be done to identify the Python code of the pair of   \n",
        "    English-Python code to be fed to the transformer model\n",
        "\n",
        "    3.The in between spaces and comments in the python code has to be \n",
        "      removed so that the model doesn't learn any unncessary stuff e.g \n",
        "      redundant new lines or #comments(in between code)  for the python \n",
        "      code generated   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOnyfeDbXwdS"
      },
      "source": [
        "Special care was taken not to use mixed-use of tabs and spaces, or use of either 4 or 3 spaces, It was made sure that should be 4 spaces only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a_qt97UQlRR"
      },
      "source": [
        "## 3.Import Libraries\n",
        "\n",
        "We'll import PyTorch, TorchText, spaCy and a few standard modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LAOn6GYN2cuQ",
        "outputId": "0081e637-14bd-4f98-a984-d5fd31181688"
      },
      "source": [
        "!pip install -U torch==1.7.0\n",
        "!pip install -U torchtext==0.8.1\n",
        "!pip install -U torchvision==0.8.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses",
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 15.0MB/s \n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 12kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchtext==0.8.1) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2020.12.5)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchtext\n",
            "  Found existing installation: torch 1.7.0\n",
            "    Uninstalling torch-1.7.0:\n",
            "      Successfully uninstalled torch-1.7.0\n",
            "  Found existing installation: torchtext 0.9.0\n",
            "    Uninstalling torchtext-0.9.0:\n",
            "      Successfully uninstalled torchtext-0.9.0\n",
            "Successfully installed torch-1.7.1 torchtext-0.8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting torchvision==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/3f/4f45249458a0dee85bff7acf4a2ac6177708253f1f318fcf6ee230fb864f/torchvision-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.0) (7.0.0)\n",
            "Collecting torch==1.7.0\n",
            "  Using cached https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.0) (0.6)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.0) (3.7.4.3)\n",
            "\u001b[31mERROR: torchtext 0.8.1 has requirement torch==1.7.1, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.1\n",
            "    Uninstalling torch-1.7.1:\n",
            "      Successfully uninstalled torch-1.7.1\n",
            "  Found existing installation: torchvision 0.9.0+cu101\n",
            "    Uninstalling torchvision-0.9.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.0+cu101\n",
            "Successfully installed torch-1.7.0 torchvision-0.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUnMLdevEzFT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data import Field\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srzErHAsEzFU"
      },
      "source": [
        "Then set a random seed for deterministic results/reproducability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_wP4J4LEzFX"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMDAkUe2ZI9F"
      },
      "source": [
        "## 4.Data Preparation/Preprocessing\n",
        "\n",
        "The Data preprocessing would be required to generated pair of \"English-Python\" to be fed to the transformer model.Special Care is taken for the following:\n",
        "\n",
        "     1.All the python code in the generated pair out of the raw dataset\n",
        "      (of course cleaned with the steps mentioned above) is having proper indentations,spaces/tabs,new line characters .\n",
        "\n",
        "    2.Special care is taken to generate a workable python code by handling indentations,\",\" , \":\", tabs,new line characters.\n",
        "\n",
        "\n",
        "    3.Python tokenizer is used to generate tokens from the python code.\n",
        "    Note:Separate tokens are taken for the following:\n",
        "\n",
        "      a)COMMENT\n",
        "\n",
        "      b)ENCODING\n",
        "\n",
        "      c)INDENT\n",
        "\n",
        "      d)DEDENT\n",
        "\n",
        "      e)NEWLINE\n",
        "\n",
        "      f)ENDMARKER \n",
        "\n",
        "\n",
        "      The following code is used to consider the above as separate tokens while tokenizing python code into tokens\n",
        "\n",
        "      try:\n",
        "        tokens = tokenize.tokenize(io.BytesIO(text.encode('utf-8')).readline)\n",
        "        for five_tuple in tokens:\n",
        "            if five_tuple.type == tokenize.COMMENT:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.ENCODING:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.INDENT:\n",
        "                python_token_list.append(\"INDENT\")\n",
        "            elif five_tuple.type == tokenize.DEDENT:\n",
        "                python_token_list.append(\"DEDENT\")\n",
        "            elif five_tuple.type == tokenize.NL or five_tuple.type == tokenize.NEWLINE:\n",
        "                python_token_list.append(\"NEWLINE\")\n",
        "            elif five_tuple.type == tokenize.ENDMARKER :\n",
        "                continue\n",
        "            else:\n",
        "                python_token_list.append(five_tuple.string)\n",
        "    except Exception:\n",
        "        raised_exception = True\n",
        "\n",
        "\n",
        "      4.The spacy tokenizer is used to generate tokens for English text\n",
        "\n",
        "      5.The python tokenizer with special handling of the tokens (explained in Item3 above) is used to generate tokens out of the python \n",
        "      code.\n",
        "\n",
        "      6.A dataframe is formed out of The spacy tokens from English text and python tokens  from Python code.\n",
        "\n",
        "      7.The dataframe from Item6 above is used as an input to the model\n",
        "\n",
        "      8.Below is the sample python tokens  generated out of python tokenizer:\n",
        "\n",
        "      {'English': ['count', 'tuple', 'elements', 'inside', 'list'],\n",
        "      'Python': ['random',\n",
        "       '=',\n",
        "       '[',\n",
        "       \"'a'\",\n",
        "       ',',\n",
        "       '(',\n",
        "       \"'a'\",\n",
        "       ',',\n",
        "       \"'b'\",\n",
        "       ')',\n",
        "       ',',\n",
        "       '(',\n",
        "       \"'a'\",\n",
        "        ',',\n",
        "       \"'b'\",\n",
        "       ')',\n",
        "       ',',\n",
        "      '[',\n",
        "      '3',\n",
        "      ',',\n",
        "      '4',\n",
        "      ']',\n",
        "      ']',\n",
        "      'NEWLINE',\n",
        "      'count',\n",
        "      '=',\n",
        "     'random',\n",
        "      '.',\n",
        "     'count',\n",
        "     '(',\n",
        "     '(',\n",
        "     \"'a'\",\n",
        "     ',',\n",
        "     \"'b'\",\n",
        "     ')',\n",
        "     ')',\n",
        "     'NEWLINE',\n",
        "     'print',\n",
        "     '(',\n",
        "        '\"The count of (\\'a\\', \\'b\\') is:\"',\n",
        "      ',',\n",
        "      'count',\n",
        "     ')',\n",
        "      'NEWLINE']}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MUSMpThh376"
      },
      "source": [
        "## 5. Data Extension Strategy\n",
        "\n",
        "There is no special data extension strategy followed.Have used the same cleaned data ,did data preprocessing and converted them into pairs\n",
        "to feed to the transformer model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hawianoFEzFY"
      },
      "source": [
        "Instantiate English spaCy models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BP3YSvJEzFY",
        "outputId": "4e2c752c-42d4-4bf0-aaf4-2d3bfea901a1"
      },
      "source": [
        "%%bash\n",
        "python -m spacy download en\n",
        "python -m spacy download de\n",
        "#spacy_de = spacy.load('de')\n",
        "#spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py): started\n",
            "  Building wheel for de-core-news-sm (setup.py): finished with status 'done'\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=d30834ccbaa59386bf2ec7dc7c765373915b378febedfa41e175d63c1227f94a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pjkyh849/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAq6OVJKfXm3"
      },
      "source": [
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bEkyPt5EzFY"
      },
      "source": [
        "For the English text spacy tokenizer is used.The below function takes \"English text\" as input and generate tokens using spacy tokenization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KaGEZ45EzFZ"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh0VITKGYz6Z"
      },
      "source": [
        "## Read the dataset from the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM34DCqNURwX",
        "outputId": "af2e60a3-1428-4dba-9772-8d7cb864568a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTGgcuylUiKH",
        "outputId": "c2bf61ec-70e2-47f9-803a-58f5c9bafb72"
      },
      "source": [
        "!ls '/content/gdrive/MyDrive/data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cornell\t\t\t\t  english-python.pt  myfile.txt       test.py\n",
            "cornell_movie_dialogs_corpus.zip  func_test.py\t     python_data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V9qZho8UnAT"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-MHoWNwUtF0",
        "outputId": "baf1d33f-5188-48c7-d6fd-9454c40d48e1"
      },
      "source": [
        "corpus_name = \"data\"\n",
        "corpus = os.path.join(\"/content/gdrive/MyDrive\", corpus_name)\n",
        "\n",
        "def printLines(file, n=10):\n",
        "    print(file)\n",
        "    with open(file, 'rb') as datafile:\n",
        "        lines = datafile.readlines()\n",
        "    for line in lines[:n]:\n",
        "        print(line)\n",
        "\n",
        "printLines(os.path.join(corpus, \"python_data.txt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/data/python_data.txt\n",
            "b'# write a python program to add two numbers \\r\\n'\n",
            "b'num1 = 1.5\\r\\n'\n",
            "b'num2 = 6.3\\r\\n'\n",
            "b'sum = num1 + num2\\r\\n'\n",
            "b\"print(f'Sum: {sum}')\\r\\n\"\n",
            "b'\\r\\n'\n",
            "b'# write a python function to add two user provided numbers and return the sum\\r\\n'\n",
            "b'def add_two_numbers(num1, num2):\\r\\n'\n",
            "b'    sum = num1 + num2\\r\\n'\n",
            "b'    return sum\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKXV-WgWNCx8"
      },
      "source": [
        "english_text_python_program_pair_list = []\n",
        "process_python_code=False\n",
        "i=1\n",
        "with open('/content/gdrive/MyDrive/data/python_data.txt', 'r', encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        #print(i)\n",
        "        i += 1\n",
        "        if process_python_code==False:\n",
        "            if line.strip() == '':\n",
        "                continue\n",
        "            if line.startswith('#'):\n",
        "                english_text = line\n",
        "                #english_text_list.append(line)\n",
        "                process_python_code=True\n",
        "                python_program=''\n",
        "            else:\n",
        "                print(i, \": \", line)            \n",
        "        else:\n",
        "            if line.strip() == '':\n",
        "                process_python_code=False\n",
        "                english_text_python_program_pair_list.append((english_text, python_program))\n",
        "                python_program=''\n",
        "                english_text =''\n",
        "            if line.lstrip().startswith('#'):\n",
        "                continue\n",
        "            else:\n",
        "                python_program += line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls-5mZrkNfzN",
        "outputId": "e8e66a66-a37e-4b55-f976-a23744e9dc6e"
      },
      "source": [
        "len(english_text_python_program_pair_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDwg8N3AxBM"
      },
      "source": [
        "english_text_list,python_program_list  = zip(*english_text_python_program_pair_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGQ_PNHLAydR"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'English': english_text_list, 'Python':python_program_list })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "HSSq3thYA276",
        "outputId": "a9b2045c-47e3-4b77-d283-6db70b3f6d4d"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Python</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td># write a python program to add two numbers \\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td># write a python function to add two user prov...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td># write a program to find and print the larges...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td># write a program to find and print the smalle...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td># Write a python function to merge two given l...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td># Write a program to check whether a number is...</td>\n",
              "      <td>num = 337\\nif num &gt; 1:\\n   for i in range(2, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td># Write a python function that prints the fact...</td>\n",
              "      <td>def print_factors(x):\\n   print(f\"The factors ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td># Write a program to find the factorial of a n...</td>\n",
              "      <td>num = 13\\nfactorial = 1\\nif num &lt; 0:\\n   print...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td># Write a python function to print whether a n...</td>\n",
              "      <td>def check_pnz(num):\\n    if num &gt; 0:\\n       p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td># Write a program to print the multiplication ...</td>\n",
              "      <td>num = 9\\nfor i in range(1, 11):\\n   print(f\"{n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English                                             Python\n",
              "0     # write a python program to add two numbers \\n  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  # write a python function to add two user prov...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  # write a program to find and print the larges...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  # write a program to find and print the smalle...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  # Write a python function to merge two given l...     def merge_lists(l1, l2):\\n    return l1 + l2\\n\n",
              "5  # Write a program to check whether a number is...  num = 337\\nif num > 1:\\n   for i in range(2, n...\n",
              "6  # Write a python function that prints the fact...  def print_factors(x):\\n   print(f\"The factors ...\n",
              "7  # Write a program to find the factorial of a n...  num = 13\\nfactorial = 1\\nif num < 0:\\n   print...\n",
              "8  # Write a python function to print whether a n...  def check_pnz(num):\\n    if num > 0:\\n       p...\n",
              "9  # Write a program to print the multiplication ...  num = 9\\nfor i in range(1, 11):\\n   print(f\"{n..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qc0oQkmBa_-",
        "outputId": "ab3a1b6f-14b8-4929-e21a-23934ee4b412"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import random\n",
        "import random\n",
        "#import google_trans_new\n",
        "#from google_trans_new import google_translator\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "lem = WordNetLemmatizer()\n",
        "#translator = google_translator()\n",
        "\n",
        "def clean_text(text):\n",
        "    ## lower case\n",
        "    if not isinstance(text, str):\n",
        "      return str(text) \n",
        "    cleaned = text.lower()\n",
        "\n",
        "    urls_pattern = re.compile(r'https?://\\S+|www.\\S+')\n",
        "    cleaned = urls_pattern.sub(r'',cleaned)\n",
        "    \n",
        "    ## remove punctuations\n",
        "    punctuations = string.punctuation\n",
        "    cleaned_temp = \"\".join(character for character in cleaned if character not in punctuations)\n",
        "    \n",
        "    ## remove stopwords \n",
        "    words = cleaned_temp.split()\n",
        "    #stopword_lists = stopwords.words(\"english\")\n",
        "    #cleaned = [word for word in words if word not in stopword_lists]\n",
        "    cleaned = words\n",
        "    \n",
        "    ## normalization - lemmatization\n",
        "    #cleaned = [lem.lemmatize(word, \"v\") for word in cleaned]\n",
        "    #cleaned = [lem.lemmatize(word, \"n\") for word in cleaned]\n",
        "    \n",
        "    ## join \n",
        "    cleaned = \" \".join(cleaned)\n",
        "    return cleaned\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "fbdd95c2dcae43f89ac74474be00b030",
            "d83603331089493a99c2200ed1647215",
            "b424d51652d947a7b6d4cb1ea86ae11c",
            "dba9536503674dac8367fd4bc787cbea",
            "28291f2a401b4984ae7c6715199ffba6",
            "8082f895449b4f58b24b740d41e30ce7",
            "5704953bab524cbcbbc7a4b10a60beff",
            "556042bf6472476caf820b9d1e1d5acd",
            "a78511c0cf3b448198e1f22e72f461f3",
            "a9c7219c2d6a4754a06e5463cea94217",
            "2ae7ccdf6ad14b3b9a1478998484a577",
            "bc14d0f349d34b8597084bde9dce7325",
            "815cd491991745d0bf63085c34fb20c0",
            "8214a830426a4d3db866270f266df229",
            "6f41d0d886e94ffb98d0b540b8ce4259",
            "0d4b26d7cf5b4f3d9efb863946074a3a"
          ]
        },
        "id": "LJnuVpb-BTFG",
        "outputId": "eb7a4a2d-4acd-454b-e4eb-fc788c2aad42"
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "tqdm().pandas() \n",
        "\n",
        "df['English'] = df['English'].progress_apply(lambda txt: clean_text(txt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbdd95c2dcae43f89ac74474be00b030",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a78511c0cf3b448198e1f22e72f461f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4727.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2b391c5646d648cba8bec1ffbd3d4ed6",
            "2d976269dffc49c4a8507c402cbecc4a",
            "ebd72e2a6f9246e0b1458834caa0a5fb",
            "ea0aeb75bbb3442cb45851258003ff41",
            "754a70a0d9664fd08dd5ee3cf9d2099f",
            "db6c0bd6756644f08126ca3e2c7e205d",
            "ae98e7b7ede34dfa812cce7ac3efae5c",
            "bcdb672db9674cb88ee322407d2c520c"
          ]
        },
        "id": "4tvulIotBvPZ",
        "outputId": "39b8f5f1-e90e-471e-f6a0-f460d3415fbc"
      },
      "source": [
        "df['Python'] = df['Python'].progress_apply(lambda txt: txt.lstrip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b391c5646d648cba8bec1ffbd3d4ed6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4727.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "JKEeJH2qCA_t",
        "outputId": "c7a36cad-a450-466a-8ff5-49c7a33f3d91"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Python</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>write a program to check whether a number is p...</td>\n",
              "      <td>num = 337\\nif num &gt; 1:\\n   for i in range(2, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>write a python function that prints the factor...</td>\n",
              "      <td>def print_factors(x):\\n   print(f\"The factors ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>write a program to find the factorial of a number</td>\n",
              "      <td>num = 13\\nfactorial = 1\\nif num &lt; 0:\\n   print...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>write a python function to print whether a num...</td>\n",
              "      <td>def check_pnz(num):\\n    if num &gt; 0:\\n       p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>write a program to print the multiplication ta...</td>\n",
              "      <td>num = 9\\nfor i in range(1, 11):\\n   print(f\"{n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English                                             Python\n",
              "0          write a python program to add two numbers  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  write a program to find and print the largest ...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= n...\n",
              "3  write a program to find and print the smallest...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  write a python function to merge two given lis...     def merge_lists(l1, l2):\\n    return l1 + l2\\n\n",
              "5  write a program to check whether a number is p...  num = 337\\nif num > 1:\\n   for i in range(2, n...\n",
              "6  write a python function that prints the factor...  def print_factors(x):\\n   print(f\"The factors ...\n",
              "7  write a program to find the factorial of a number  num = 13\\nfactorial = 1\\nif num < 0:\\n   print...\n",
              "8  write a python function to print whether a num...  def check_pnz(num):\\n    if num > 0:\\n       p...\n",
              "9  write a program to print the multiplication ta...  num = 9\\nfor i in range(1, 11):\\n   print(f\"{n..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBDXgbNxvbdo"
      },
      "source": [
        "import tokenize\n",
        "import io\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_python(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Python Code to list of strings\n",
        "    \"\"\"\n",
        "    python_token_list = []\n",
        "    raised_exception = False\n",
        "    try:\n",
        "        tokens = tokenize.tokenize(io.BytesIO(text.encode('utf-8')).readline)\n",
        "        for five_tuple in tokens:\n",
        "            if five_tuple.type == tokenize.COMMENT:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.ENCODING:\n",
        "                continue\n",
        "            elif five_tuple.type == tokenize.INDENT:\n",
        "                python_token_list.append(\"INDENT\")\n",
        "            elif five_tuple.type == tokenize.DEDENT:\n",
        "                python_token_list.append(\"DEDENT\")\n",
        "            elif five_tuple.type == tokenize.NL or five_tuple.type == tokenize.NEWLINE:\n",
        "                python_token_list.append(\"NEWLINE\")\n",
        "            elif five_tuple.type == tokenize.ENDMARKER :\n",
        "                continue\n",
        "            else:\n",
        "                python_token_list.append(five_tuple.string)\n",
        "    except Exception:\n",
        "        raised_exception = True\n",
        "        #print( \"Exception: \", Exception, \" program: \", text)\n",
        "    return python_token_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1U6dt9CHpSS",
        "outputId": "482b8bf5-4388-4731-c773-3aa35f5d889c"
      },
      "source": [
        "SRC = Field(tokenize=tokenize_en, \n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>',            \n",
        "            batch_first = True, \n",
        "            lower=True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_python, \n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>', \n",
        "            batch_first = True\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Cq9YpFCF14"
      },
      "source": [
        "fields = [('English', SRC),('Python',TRG)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNpkuJq7HoUg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, valid = train_test_split(df, test_size=0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jES070ThIBNq"
      },
      "source": [
        "train = train.reset_index(drop=True) ## This is being done because data.Example.fromlist was failing\n",
        "valid = valid.reset_index(drop=True) ## This is being done because data.Example.fromlist was failing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1ueu0PaIEma"
      },
      "source": [
        "MAX_OUTPUT_SEQ_LENGTH = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvn85iFZIUzt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qtkkMweIKY9",
        "outputId": "07c9e249-aeb1-473b-fce8-7f8ef4b6d232"
      },
      "source": [
        "example_trng = [Example.fromlist([train.English[i],train.Python[i]], fields) for i in range(train.shape[0]) if len(tokenize_python(train.Python[i])) <= MAX_OUTPUT_SEQ_LENGTH - 4 ] \n",
        "example_val = [Example.fromlist([valid.English[i],valid.Python[i]], fields) for i in range(valid.shape[0]) if len(tokenize_python(valid.Python[i])) <= MAX_OUTPUT_SEQ_LENGTH - 4 ] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXAK2LlqIdsl"
      },
      "source": [
        "train_dataset = Dataset(example_trng, fields)\n",
        "valid_dataset = Dataset(example_val, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKgtTU38Io2s",
        "outputId": "d37a078a-a948-4f79-9fdc-8314a3aca48e"
      },
      "source": [
        "vars(train_dataset.examples[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'English': ['write',\n",
              "  'a',\n",
              "  'function',\n",
              "  'to',\n",
              "  'calculate',\n",
              "  'the',\n",
              "  'volume',\n",
              "  'v',\n",
              "  'of',\n",
              "  'ideal',\n",
              "  'gas',\n",
              "  'based',\n",
              "  'on',\n",
              "  'ideal',\n",
              "  'gas',\n",
              "  'equation',\n",
              "  'pressure',\n",
              "  'p',\n",
              "  'and',\n",
              "  'tempreature',\n",
              "  't',\n",
              "  'given'],\n",
              " 'Python': ['def',\n",
              "  'find_volume_of_ideal_gas',\n",
              "  '(',\n",
              "  'pressure',\n",
              "  ':',\n",
              "  'float',\n",
              "  ',',\n",
              "  'temp',\n",
              "  ':',\n",
              "  'float',\n",
              "  ',',\n",
              "  'n',\n",
              "  ':',\n",
              "  'float',\n",
              "  ')',\n",
              "  '->',\n",
              "  'float',\n",
              "  ':',\n",
              "  'NEWLINE',\n",
              "  'INDENT',\n",
              "  'r',\n",
              "  '=',\n",
              "  '8.3145',\n",
              "  'NEWLINE',\n",
              "  'return',\n",
              "  '(',\n",
              "  'n',\n",
              "  '*',\n",
              "  'r',\n",
              "  '*',\n",
              "  'temp',\n",
              "  ')',\n",
              "  '/',\n",
              "  'pressure',\n",
              "  'NEWLINE',\n",
              "  'DEDENT']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGNIQV0-Ir_3",
        "outputId": "6d373b9f-bccb-4007-a702-553d3d639238"
      },
      "source": [
        "vars(valid_dataset.examples[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'English': ['write',\n",
              "  'a',\n",
              "  'python',\n",
              "  'function',\n",
              "  'to',\n",
              "  'count',\n",
              "  'the',\n",
              "  'number',\n",
              "  'of',\n",
              "  'lines',\n",
              "  'in',\n",
              "  'a',\n",
              "  'text',\n",
              "  'file'],\n",
              " 'Python': ['def',\n",
              "  'check_lines',\n",
              "  '(',\n",
              "  ')',\n",
              "  ':',\n",
              "  'NEWLINE',\n",
              "  'INDENT',\n",
              "  'fname',\n",
              "  '=',\n",
              "  'input',\n",
              "  '(',\n",
              "  '\"file name: \"',\n",
              "  ')',\n",
              "  'NEWLINE',\n",
              "  'num_lines',\n",
              "  '=',\n",
              "  '0',\n",
              "  'NEWLINE',\n",
              "  'with',\n",
              "  'open',\n",
              "  '(',\n",
              "  'fname',\n",
              "  ',',\n",
              "  \"'r'\",\n",
              "  ')',\n",
              "  'as',\n",
              "  'f',\n",
              "  ':',\n",
              "  'NEWLINE',\n",
              "  'INDENT',\n",
              "  'for',\n",
              "  'line',\n",
              "  'in',\n",
              "  'f',\n",
              "  ':',\n",
              "  'NEWLINE',\n",
              "  'INDENT',\n",
              "  'num_lines',\n",
              "  '+=',\n",
              "  '1',\n",
              "  'NEWLINE',\n",
              "  'DEDENT',\n",
              "  'DEDENT',\n",
              "  'print',\n",
              "  '(',\n",
              "  '\"Number of lines = \"',\n",
              "  ',',\n",
              "  'num_lines',\n",
              "  ')',\n",
              "  'NEWLINE',\n",
              "  'DEDENT']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUd2-nQ6I220"
      },
      "source": [
        "SRC.build_vocab(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJI4EpB1I4NG"
      },
      "source": [
        "TRG.build_vocab(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dmsx1WvEtwE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fhx__qZF3Hx"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Y7dJieF7CI",
        "outputId": "7833af13-7f65-4623-ae7d-b02e7933a6ce"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_dataset, valid_dataset), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x:len(x.English),\n",
        "    sort_within_batch = False, \n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcuPfeokiQt8"
      },
      "source": [
        "## 6. Model Architecture\n",
        "\n",
        "\n",
        "The Model used is **transformers with self-attention, multi-head, and scaled-dot product attention**\n",
        "\n",
        "The model is implemented from [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078). This model will achieve improved test perplexity whilst only using a single layer RNN in both the encoder and the decoder.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The general encoder-decoder model.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq1.png?raw=1)\n",
        "\n",
        "We use our encoder (green) over the embedded source sequence (yellow) to create a context vector (red). We then use that context vector with the decoder (blue) and a linear layer (purple) to generate the target sentence.\n",
        "\n",
        "the older models, we used an multi-layered LSTM as the encoder and decoder.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq4.png?raw=1)\n",
        "\n",
        "One downside of the previous model is that the decoder is trying to cram lots of information into the hidden states. Whilst decoding, the hidden state will need to contain information about the whole of the source sequence, as well as all of the tokens have been decoded so far. By alleviating some of this information compression, we can create a better model!\n",
        "\n",
        "We'll also be using a GRU (Gated Recurrent Unit) instead of an LSTM (Long Short-Term Memory). Why? Mainly because that's what they did in the paper (this paper also introduced GRUs) and also because we used LSTMs last time. To understand how GRUs (and LSTMs) differ from standard RNNS, check out [this](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) link. Is a GRU better than an LSTM? [Research](https://arxiv.org/abs/1412.3555) has shown they're pretty much the same, and both are better than standard RNNs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-symyN1zV-_q"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jarF42K0WNOX"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqJrb9iLWUHK"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqfGHRX9WZZf"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv8nGIYIWHgY"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVmuR1X_Wgi4"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIjpYdO4Wm7s"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVnrgIhbWtaG"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yESIrDzr0mNi",
        "outputId": "22e6bc65-d723-4976-bb2e-5fca4ce62952"
      },
      "source": [
        "print(OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEpPZIpK2-5x",
        "outputId": "81ed5d10-cb59-4d5d-b8cf-b407c113171f"
      },
      "source": [
        "print(INPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0KBqQ2BWxuk"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsZC-bHkW3CT",
        "outputId": "a08e5494-d9cc-4c5e-cc23-19377320a7bb"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 6,950,328 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3koKqh6GW7m4"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKj7voEHXArd"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juEcz_WrXFeY"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnrl6DgqXJet"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5HKu_FFXOQp"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.English\n",
        "        trg = batch.Python\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        print(trg.shape)\n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6xj2J-tXT8B"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.English\n",
        "            trg = batch.Python\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            SRC.build_vocab(train_dataset)\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0idGzciCXae0"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJiU-8agXet8",
        "outputId": "1eb9edc9-62b3-4c0f-841c-938bb4345915"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 01 | Time: 0m 5s\n",
            "\tTrain Loss: 5.881 | Train PPL: 358.102\n",
            "\t Val. Loss: 4.354 |  Val. PPL:  77.791\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 02 | Time: 0m 5s\n",
            "\tTrain Loss: 3.738 | Train PPL:  42.009\n",
            "\t Val. Loss: 3.091 |  Val. PPL:  21.992\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 86])\n",
            "torch.Size([49, 85])\n",
            "Epoch: 03 | Time: 0m 5s\n",
            "\tTrain Loss: 2.883 | Train PPL:  17.873\n",
            "\t Val. Loss: 2.577 |  Val. PPL:  13.161\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 86])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 04 | Time: 0m 5s\n",
            "\tTrain Loss: 2.458 | Train PPL:  11.687\n",
            "\t Val. Loss: 2.250 |  Val. PPL:   9.490\n",
            "torch.Size([128, 85])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 05 | Time: 0m 5s\n",
            "\tTrain Loss: 2.157 | Train PPL:   8.646\n",
            "\t Val. Loss: 2.005 |  Val. PPL:   7.428\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([49, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 06 | Time: 0m 5s\n",
            "\tTrain Loss: 1.918 | Train PPL:   6.806\n",
            "\t Val. Loss: 1.790 |  Val. PPL:   5.990\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 07 | Time: 0m 5s\n",
            "\tTrain Loss: 1.723 | Train PPL:   5.601\n",
            "\t Val. Loss: 1.643 |  Val. PPL:   5.173\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 88])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 08 | Time: 0m 5s\n",
            "\tTrain Loss: 1.535 | Train PPL:   4.644\n",
            "\t Val. Loss: 1.521 |  Val. PPL:   4.578\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([49, 87])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 09 | Time: 0m 5s\n",
            "\tTrain Loss: 1.389 | Train PPL:   4.010\n",
            "\t Val. Loss: 1.414 |  Val. PPL:   4.113\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([49, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "Epoch: 10 | Time: 0m 5s\n",
            "\tTrain Loss: 1.242 | Train PPL:   3.462\n",
            "\t Val. Loss: 1.338 |  Val. PPL:   3.810\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([49, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 11 | Time: 0m 5s\n",
            "\tTrain Loss: 1.113 | Train PPL:   3.045\n",
            "\t Val. Loss: 1.268 |  Val. PPL:   3.554\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 12 | Time: 0m 5s\n",
            "\tTrain Loss: 1.006 | Train PPL:   2.735\n",
            "\t Val. Loss: 1.220 |  Val. PPL:   3.388\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([49, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 13 | Time: 0m 6s\n",
            "\tTrain Loss: 0.915 | Train PPL:   2.497\n",
            "\t Val. Loss: 1.150 |  Val. PPL:   3.160\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 14 | Time: 0m 6s\n",
            "\tTrain Loss: 0.832 | Train PPL:   2.297\n",
            "\t Val. Loss: 1.120 |  Val. PPL:   3.063\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([49, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 15 | Time: 0m 6s\n",
            "\tTrain Loss: 0.755 | Train PPL:   2.127\n",
            "\t Val. Loss: 1.095 |  Val. PPL:   2.990\n",
            "torch.Size([128, 93])\n",
            "torch.Size([49, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 16 | Time: 0m 6s\n",
            "\tTrain Loss: 0.687 | Train PPL:   1.988\n",
            "\t Val. Loss: 1.051 |  Val. PPL:   2.859\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 85])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 17 | Time: 0m 6s\n",
            "\tTrain Loss: 0.623 | Train PPL:   1.864\n",
            "\t Val. Loss: 1.045 |  Val. PPL:   2.844\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 18 | Time: 0m 6s\n",
            "\tTrain Loss: 0.571 | Train PPL:   1.771\n",
            "\t Val. Loss: 1.029 |  Val. PPL:   2.798\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 19 | Time: 0m 6s\n",
            "\tTrain Loss: 0.522 | Train PPL:   1.686\n",
            "\t Val. Loss: 1.003 |  Val. PPL:   2.727\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([49, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 20 | Time: 0m 6s\n",
            "\tTrain Loss: 0.479 | Train PPL:   1.614\n",
            "\t Val. Loss: 0.992 |  Val. PPL:   2.697\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 21 | Time: 0m 6s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.555\n",
            "\t Val. Loss: 1.005 |  Val. PPL:   2.731\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([49, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 22 | Time: 0m 6s\n",
            "\tTrain Loss: 0.411 | Train PPL:   1.508\n",
            "\t Val. Loss: 0.989 |  Val. PPL:   2.687\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([49, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 23 | Time: 0m 5s\n",
            "\tTrain Loss: 0.377 | Train PPL:   1.458\n",
            "\t Val. Loss: 0.972 |  Val. PPL:   2.642\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 24 | Time: 0m 6s\n",
            "\tTrain Loss: 0.353 | Train PPL:   1.424\n",
            "\t Val. Loss: 0.969 |  Val. PPL:   2.635\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 25 | Time: 0m 5s\n",
            "\tTrain Loss: 0.322 | Train PPL:   1.380\n",
            "\t Val. Loss: 0.978 |  Val. PPL:   2.659\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 83])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([49, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 26 | Time: 0m 6s\n",
            "\tTrain Loss: 0.308 | Train PPL:   1.361\n",
            "\t Val. Loss: 0.970 |  Val. PPL:   2.638\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([49, 94])\n",
            "Epoch: 27 | Time: 0m 5s\n",
            "\tTrain Loss: 0.283 | Train PPL:   1.327\n",
            "\t Val. Loss: 0.975 |  Val. PPL:   2.650\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([49, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 28 | Time: 0m 6s\n",
            "\tTrain Loss: 0.267 | Train PPL:   1.306\n",
            "\t Val. Loss: 0.969 |  Val. PPL:   2.636\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 90])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 29 | Time: 0m 5s\n",
            "\tTrain Loss: 0.252 | Train PPL:   1.286\n",
            "\t Val. Loss: 0.984 |  Val. PPL:   2.676\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 83])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 30 | Time: 0m 5s\n",
            "\tTrain Loss: 0.233 | Train PPL:   1.262\n",
            "\t Val. Loss: 0.991 |  Val. PPL:   2.693\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 31 | Time: 0m 6s\n",
            "\tTrain Loss: 0.224 | Train PPL:   1.251\n",
            "\t Val. Loss: 0.984 |  Val. PPL:   2.676\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 32 | Time: 0m 6s\n",
            "\tTrain Loss: 0.211 | Train PPL:   1.235\n",
            "\t Val. Loss: 0.978 |  Val. PPL:   2.659\n",
            "torch.Size([128, 95])\n",
            "torch.Size([49, 87])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 33 | Time: 0m 6s\n",
            "\tTrain Loss: 0.204 | Train PPL:   1.227\n",
            "\t Val. Loss: 0.981 |  Val. PPL:   2.667\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 34 | Time: 0m 5s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 0.995 |  Val. PPL:   2.706\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 35 | Time: 0m 5s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.003 |  Val. PPL:   2.726\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 84])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 36 | Time: 0m 5s\n",
            "\tTrain Loss: 0.172 | Train PPL:   1.187\n",
            "\t Val. Loss: 0.997 |  Val. PPL:   2.710\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 90])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 89])\n",
            "Epoch: 37 | Time: 0m 5s\n",
            "\tTrain Loss: 0.165 | Train PPL:   1.180\n",
            "\t Val. Loss: 1.016 |  Val. PPL:   2.761\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 86])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 38 | Time: 0m 5s\n",
            "\tTrain Loss: 0.157 | Train PPL:   1.170\n",
            "\t Val. Loss: 1.021 |  Val. PPL:   2.777\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 86])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([49, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "Epoch: 39 | Time: 0m 5s\n",
            "\tTrain Loss: 0.152 | Train PPL:   1.164\n",
            "\t Val. Loss: 1.012 |  Val. PPL:   2.752\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 86])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 40 | Time: 0m 5s\n",
            "\tTrain Loss: 0.145 | Train PPL:   1.156\n",
            "\t Val. Loss: 1.038 |  Val. PPL:   2.824\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 85])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 41 | Time: 0m 5s\n",
            "\tTrain Loss: 0.139 | Train PPL:   1.150\n",
            "\t Val. Loss: 1.048 |  Val. PPL:   2.851\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 42 | Time: 0m 5s\n",
            "\tTrain Loss: 0.137 | Train PPL:   1.147\n",
            "\t Val. Loss: 1.044 |  Val. PPL:   2.841\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([49, 91])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "Epoch: 43 | Time: 0m 6s\n",
            "\tTrain Loss: 0.128 | Train PPL:   1.137\n",
            "\t Val. Loss: 1.033 |  Val. PPL:   2.809\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 44 | Time: 0m 5s\n",
            "\tTrain Loss: 0.125 | Train PPL:   1.133\n",
            "\t Val. Loss: 1.065 |  Val. PPL:   2.900\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 45 | Time: 0m 6s\n",
            "\tTrain Loss: 0.119 | Train PPL:   1.127\n",
            "\t Val. Loss: 1.056 |  Val. PPL:   2.874\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([49, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 87])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 46 | Time: 0m 5s\n",
            "\tTrain Loss: 0.116 | Train PPL:   1.123\n",
            "\t Val. Loss: 1.054 |  Val. PPL:   2.868\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([49, 92])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "Epoch: 47 | Time: 0m 6s\n",
            "\tTrain Loss: 0.113 | Train PPL:   1.119\n",
            "\t Val. Loss: 1.072 |  Val. PPL:   2.921\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 83])\n",
            "torch.Size([128, 91])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 88])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([49, 95])\n",
            "torch.Size([128, 97])\n",
            "Epoch: 48 | Time: 0m 6s\n",
            "\tTrain Loss: 0.110 | Train PPL:   1.116\n",
            "\t Val. Loss: 1.075 |  Val. PPL:   2.930\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 89])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 86])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 49 | Time: 0m 6s\n",
            "\tTrain Loss: 0.108 | Train PPL:   1.114\n",
            "\t Val. Loss: 1.073 |  Val. PPL:   2.924\n",
            "torch.Size([128, 97])\n",
            "torch.Size([49, 83])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 93])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 92])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 95])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 94])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 90])\n",
            "torch.Size([128, 98])\n",
            "torch.Size([128, 96])\n",
            "torch.Size([128, 97])\n",
            "torch.Size([128, 96])\n",
            "Epoch: 50 | Time: 0m 5s\n",
            "\tTrain Loss: 0.102 | Train PPL:   1.108\n",
            "\t Val. Loss: 1.083 |  Val. PPL:   2.953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNZE4JsVQbKQ"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/gdrive/MyDrive/data/tut6-model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBwOM7zilXFM"
      },
      "source": [
        "## 7. Evaluation Metric\n",
        "The model is used to acheive the perplexity.The perplexity is used as the evaluation metric.\n",
        "\n",
        "We acheived a test perplexity of **2.202**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yTEeDuReBLK",
        "outputId": "b683604f-6a4d-4132-8324-d3994cf95a5d"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/data/tut6-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.083 | Test PPL:   2.953 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8C93617myYj"
      },
      "source": [
        "## 8.Model Prediction\n",
        "\n",
        "Now that the transformer model is trained.We would be using the model to predict the python code generated in case an \"English Text\" is given as input to the Model\n",
        "\n",
        "Also the python code generated is in the form of tokens.This has to further formatted to generate appropriate python code.\n",
        "\n",
        "\n",
        "A python intepreter has to be used to run the generated python code to verify if its working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLufM2mGeOtp"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqa7KbWyeme4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3beb2870-e343-42d3-c733-770eac6f9edc"
      },
      "source": [
        "example_idx = 0\n",
        "\n",
        "src = vars(train_dataset.examples[example_idx])['English']\n",
        "trg = vars(train_dataset.examples[example_idx])['Python']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['define', 'a', 'function', 'that', 'can', 'accept', 'an', 'integer', 'number', 'as', 'input', 'and', 'print', 'the', 'it', 'is', 'an', 'even', 'number', 'if', 'the', 'number', 'is', 'even', 'otherwise', 'print', 'it', 'is', 'an', 'odd', 'number']\n",
            "trg = ['def', 'even_or_odd_num', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'if', 'n', '%', '2', '==', '0', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an even number\"', ')', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an odd number\"', ')', 'NEWLINE', 'DEDENT', 'DEDENT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8lVDbmXfQfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a697aa-f069-4c93-cac6-d4a1218f5c66"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['def', 'even_or_odd_num', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'if', 'n', '%', '2', '==', '0', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an even number\"', ')', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an odd number\"', ')', 'NEWLINE', 'DEDENT', 'DEDENT', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tdwzQnNloLA"
      },
      "source": [
        "## 8.Generate Python Code\n",
        "Utilities to be written to generate python code.\n",
        "This utility will first format the python code generated out of model prediction so that the same can be executed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MwLbPiLl5lq"
      },
      "source": [
        "#### Format to Python code utility which reads the predicted list of tokens and converts it to python code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSeg_b9_Rf0t"
      },
      "source": [
        "import tokenize\n",
        "def format_to_python_code(list_tokens):\n",
        "  final_list = []\n",
        "  for i in range(len(list_tokens)):\n",
        "  #print(list_test2_mod[i],list_test2_mod[i] == 'NEWLINE')\n",
        "  #final_list.append(list_test2_mod[i])\n",
        "    if i > 0:\n",
        "      if i+1 < len(list_tokens) and list_tokens[i-1] != 'NEWLINE':\n",
        "      #print(list_test_mod[i],(list_test_mod[i+1] == 'NEWLINE'))\n",
        "        p = i -1\n",
        "        if list_tokens[i] != 'NEWLINE' and list_tokens[p] != 'NEWLINE' and  list_tokens[i] != 'INDENT' and  list_tokens[p] != 'INDENT':\n",
        "            final_list.append(' ')\n",
        "  #if list_test2_mod[i] == tokenize.COMMENT:\n",
        "                #continue\n",
        "  #elif list_test2_mod[i] == tokenize.ENCODING:\n",
        "                #continue\n",
        "    if list_tokens[i] == 'INDENT':\n",
        "                  final_list.append(\"  \")\n",
        "    elif list_tokens[i] == 'DEDENT':\n",
        "                #final_list.append(' ')\n",
        "                  continue\n",
        "    elif list_tokens[i] == 'NEWLINE':\n",
        "                  #print(\"Adding new line\")\n",
        "                  final_list.append(\"\\n\")\n",
        "    elif list_tokens[i] == 'return':\n",
        "      final_list.append(\"  \"+list_tokens[i])              \n",
        "    else:\n",
        "      final_list.append(list_tokens[i])\n",
        "\n",
        "  #elif list_test2_mod[i] == tokenize.ENDMARKER :\n",
        "                #continue\n",
        "\n",
        "  return final_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggP0LQuNmGyg"
      },
      "source": [
        "#### Sample Python code output generated out of the format python code utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYuzH6hVXvHF",
        "outputId": "d27bafbb-10c6-4020-e0a0-b8fb7e50cff6"
      },
      "source": [
        "file1 = open(\"/content/gdrive/MyDrive/data/python1.py\",\"w\") \n",
        "#L = [\"This is Delhi \\n\",\"This is Paris \\n\",\"This is London \\n\"]  \n",
        "  \n",
        "# \\n is placed to indicate EOL (End of Line) \n",
        "#file1.write(\"Hello \\n\") \n",
        "file1.writelines(format_to_python_code(translation[:-1])) \n",
        "file1.close() #to change file access modes \n",
        "  \n",
        "file1 = open(\"/content/gdrive/MyDrive/data/python1.py\",\"r+\")  \n",
        "  \n",
        "print (\"Output of Read function is \")\n",
        "print (file1.read()) \n",
        "print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of Read function is \n",
            "st = \"Where is this going? Could you please help me understand!\"\n",
            "vowels = \"AEIOUaeiou\"\n",
            "for v in vowels :\n",
            "  st = st . replace ( v , '_' )\n",
            " print ( st )\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlpVqymUgHLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8749f6fa-0598-4f90-df83-83f8ba93a062"
      },
      "source": [
        "example_idx = 1\n",
        "\n",
        "src = vars(train_dataset.examples[example_idx])['English']\n",
        "trg = vars(train_dataset.examples[example_idx])['Python']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'program', 'to', 'print', 'a', 'given', 'string', 'replacing', 'all', 'the', 'vowels', 'with']\n",
            "trg = ['st', '=', '\"Where is this going? Could you please help me understand!\"', 'NEWLINE', 'vowels', '=', '\"AEIOUaeiou\"', 'NEWLINE', 'for', 'v', 'in', 'vowels', ':', 'NEWLINE', 'INDENT', 'st', '=', 'st', '.', 'replace', '(', 'v', ',', \"'_'\", ')', 'NEWLINE', 'DEDENT', 'print', '(', 'st', ')', 'NEWLINE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcgS8xRAgMOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f40a2c4-f398-4972-fdde-8a553a9a7f80"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['st', '=', '\"Where is this going? Could you please help me understand!\"', 'NEWLINE', 'vowels', '=', '\"AEIOUaeiou\"', 'NEWLINE', 'for', 'v', 'in', 'vowels', ':', 'NEWLINE', 'INDENT', 'st', '=', 'st', '.', 'replace', '(', 'v', ',', \"'_'\", ')', 'NEWLINE', 'DEDENT', 'print', '(', 'st', ')', 'NEWLINE', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I216MvjwcG4D",
        "outputId": "7fb3eadb-a22b-430a-dd2d-36a3e62a5a06"
      },
      "source": [
        "file1 = open(\"/content/gdrive/MyDrive/data/python2.py\",\"w\") \n",
        "#L = [\"This is Delhi \\n\",\"This is Paris \\n\",\"This is London \\n\"]  \n",
        "  \n",
        "# \\n is placed to indicate EOL (End of Line) \n",
        "#file1.write(\"Hello \\n\") \n",
        "file1.writelines(format_python_program(translation[:-1])) \n",
        "file1.close() #to change file access modes \n",
        "  \n",
        "file1 = open(\"/content/gdrive/MyDrive/data/python2.py\",\"r+\")  \n",
        "  \n",
        "print (\"Output of Read function is \")\n",
        "print (file1.read()) \n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of Read function is \n",
            "st = \"Where is this going? Could you please help me understand!\"\n",
            "vowels = \"AEIOUaeiou\"\n",
            "for v in vowels :\n",
            "\t st = st . replace ( v , '_' )\n",
            " print ( st )\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DqA--CGdVw4",
        "outputId": "b7159738-9ed6-4ed4-f0bb-ec27ba55a5b3"
      },
      "source": [
        "example_idx = 3\n",
        "\n",
        "src = vars(train_dataset.examples[example_idx])['English']\n",
        "trg = vars(train_dataset.examples[example_idx])['Python']\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['python', 'sigmoid', 'function']\n",
            "trg = ['def', 'sigmoid_activation', '(', 'l', ')', ':', 'NEWLINE', 'INDENT', 'return', '[', 'round', '(', '1', '/', '(', '1', '+', 'math', '.', 'exp', '(', '-', 'x', ')', ')', ',', '2', ')', 'for', 'x', 'in', 'l', ']', 'NEWLINE', 'DEDENT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoVLQ-MKdnlc"
      },
      "source": [
        "file1 = open(\"/content/gdrive/MyDrive/data/python3.py\",\"w\") \n",
        "#L = [\"This is Delhi \\n\",\"This is Paris \\n\",\"This is London \\n\"]  \n",
        "  \n",
        "# \\n is placed to indicate EOL (End of Line) \n",
        "#file1.write(\"Hello \\n\") \n",
        "file1.writelines(format_python_program(translation[:-1])) \n",
        "file1.close() #to change file access modes \n",
        "  \n",
        "file1 = open(\"/content/gdrive/MyDrive/data/python2.py\",\"r+\")  \n",
        "  \n",
        "print (\"Output of Read function is \")\n",
        "print (file1.read()) \n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCpbuTUcde23",
        "outputId": "7932095a-b8c3-4f8d-d574-a738d8b356e0"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['def', 'sigmoid_activation', '(', 'l', ')', ':', 'NEWLINE', 'INDENT', 'return', '[', 'round', '(', '1', '/', '(', '1', '+', 'math', '.', 'exp', '(', '-', 'x', ')', ')', ',', '2', ')', 'for', 'x', 'in', 'l', ']', 'NEWLINE', 'DEDENT', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vU7beGXdjL-",
        "outputId": "78b4b41b-410b-43bb-d362-c5586598879a"
      },
      "source": [
        "#format_to_python_code\n",
        "\n",
        "file1 = open(\"/content/gdrive/MyDrive/data/python3.py\",\"w\") \n",
        "#L = [\"This is Delhi \\n\",\"This is Paris \\n\",\"This is London \\n\"]  \n",
        "  \n",
        "# \\n is placed to indicate EOL (End of Line) \n",
        "#file1.write(\"Hello \\n\") \n",
        "file1.writelines(format_to_python_code(translation[:-1])) \n",
        "file1.close() #to change file access modes \n",
        "  \n",
        "file1 = open(\"/content/gdrive/MyDrive/data/python3.py\",\"r+\")  \n",
        "  \n",
        "print (\"Output of Read function is \")\n",
        "print (file1.read()) \n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of Read function is \n",
            "def sigmoid_activation ( l ) :\n",
            "    return [ round ( 1 / ( 1 + math . exp ( - x ) ) , 2 ) for x in l ]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0NynLajmX_X"
      },
      "source": [
        "### Conver to python utility which  uses the index of the data set predicts the model output,format to python code and saves it to .py file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMN-Cw1newkZ"
      },
      "source": [
        "def convert_to_python(example_idx):\n",
        "  src = vars(train_dataset.examples[example_idx])['English']\n",
        "  trg = vars(train_dataset.examples[example_idx])['Python']\n",
        "\n",
        "  print(f'src = {src}')\n",
        "  print(f'trg = {trg}')\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  print(f'predicted trg = {translation}')\n",
        "  filename=\"/content/gdrive/MyDrive/data/\" + \"python\" + str(example_idx) +\".py\"\n",
        "  print(filename)\n",
        "  file1 = open(filename,\"w\") \n",
        "  #L = [\"This is Delhi \\n\",\"This is Paris \\n\",\"This is London \\n\"]  \n",
        "  \n",
        "  # \\n is placed to indicate EOL (End of Line) \n",
        "  #file1.write(\"Hello \\n\") \n",
        "  file1.writelines(format_to_python_code(translation[:-1])) \n",
        "  file1.close() #to change file access modes \n",
        "  \n",
        "  file1 = open(filename,\"r+\")  \n",
        "  \n",
        "  print (\"Output of Read function is \\n \")\n",
        "  print(\"==================================================\")\n",
        "  print (file1.read()) \n",
        "  print()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcNyefIlmTvM"
      },
      "source": [
        "#### Sample Output generated out of Convert to python code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKcTDV_tgGS1",
        "outputId": "0cf742ae-776e-4a93-a069-35ff563f89bb"
      },
      "source": [
        "convert_to_python(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'program', 'which', 'takes', 'user', 'input', 'tuple', 'and', 'prints', 'length', 'of', 'each', 'tuple', 'element']\n",
            "trg = ['userInput', '=', 'input', '(', '\"Enter a tuple:\"', ')', 'NEWLINE', 'x', '=', 'map', '(', 'lambda', 'x', ':', 'len', '(', 'x', ')', ',', 'tuple', '(', 'x', '.', 'strip', '(', ')', 'for', 'x', 'in', 'userInput', '.', 'split', '(', \"','\", ')', ')', ')', 'NEWLINE', 'print', '(', 'list', '(', 'x', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['userInput', '=', 'input', '(', '\"Enter a tuple:\"', ')', 'NEWLINE', 'x', '=', 'map', '(', 'lambda', 'x', ':', 'len', '(', 'x', ')', ',', 'tuple', '(', 'x', '.', 'strip', '(', ')', 'for', 'x', 'in', 'userInput', '.', 'split', '(', \"','\", ')', ')', ')', 'NEWLINE', 'print', '(', 'list', '(', 'x', ')', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python4.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "userInput = input ( \"Enter a tuple:\" )\n",
            "x = map ( lambda x : len ( x ) , tuple ( x . strip ( ) for x in userInput . split ( ',' ) ) )\n",
            "print ( list ( x ) )\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlwXgcUihGMR",
        "outputId": "9bf98e53-46be-457d-c37d-a87fc63b9e6f"
      },
      "source": [
        "convert_to_python(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'function', 'that', 'takes', 'in', 'two', 'numbers', 'and', 'returns', 'their', 'hcf']\n",
            "trg = ['def', 'hcf', '(', 'num1', ',', 'num2', ')', ':', 'NEWLINE', 'INDENT', 'smaller', '=', 'num1', 'if', 'num1', '<', 'num2', 'else', 'num2', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', 'smaller', '+', '1', ')', ':', 'NEWLINE', 'INDENT', 'if', '(', 'num1', '%', 'i', '==', '0', ')', 'and', '(', 'num2', '%', 'i', '==', '0', ')', ':', 'NEWLINE', 'INDENT', 'hcf', '=', 'i', 'NEWLINE', 'DEDENT', 'DEDENT', 'return', 'hcf', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'hcf', '(', 'num1', ',', 'num2', ')', ':', 'NEWLINE', 'INDENT', 'smaller', '=', 'num1', 'if', 'num1', '<', 'num2', 'else', 'num2', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', 'smaller', '+', '1', ')', ':', 'NEWLINE', 'INDENT', 'if', '(', 'num1', '%', 'i', '==', '0', ')', 'and', '(', 'num2', '%', 'i', '==', '0', ')']\n",
            "/content/gdrive/MyDrive/data/python6.py\n",
            "Output of Read function is \n",
            "def hcf ( num1 , num2 ) :\n",
            "  smaller = num1 if num1 < num2 else num2\n",
            "for i in range ( 1 , smaller + 1 ) :\n",
            "  if ( num1 % i == 0 ) and ( num2 % i ==0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlSRnP74hjzQ",
        "outputId": "8334524f-7cf0-4272-9a99-b7261149b3f8"
      },
      "source": [
        "convert_to_python(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['define', 'a', 'class', 'named', 'american', 'and', 'its', 'subclass', 'newyorker']\n",
            "trg = ['class', 'American', '(', 'object', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT', 'class', 'NewYorker', '(', 'American', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['class', 'American', '(', 'object', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT', 'class', 'NewYorker', '(', 'American', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python7.py\n",
            "Output of Read function is \n",
            "class American ( object ) :\n",
            "  pass\n",
            " class NewYorker ( American ) :\n",
            "  pass\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxU2CjDkh0Gs",
        "outputId": "70fa9ca7-afc1-49d4-a9a8-6d2288ae20c4"
      },
      "source": [
        "convert_to_python(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'function', 'to', 'calculate', 'the', 'compound', 'interest', 'for', 'principal', 'p', 'rate', 'r', 'and', 'time', 'in', 'years', 'y']\n",
            "trg = ['def', 'get_ci', '(', 'p', ':', 'float', ',', 'r', ':', 'float', ',', 't', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'return', 'round', '(', 'p', '*', '(', '(', '1', '+', '(', 'r', '/', '(', 'n', '*', '100', ')', ')', ')', '**', '(', 'n', '*', 't', ')', ')', '-', 'p', ',', '2', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'get_ci', '(', 'p', ':', 'float', ',', 'r', ':', 'float', ',', 't', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'return', 'round', '(', 'p', '*', '(', '(', '1', '+', '(', 'r', '/', '(', 'n', '*', '100', ')', ')', ')', '**', '(', 'n', '*', 't', ')', '-']\n",
            "/content/gdrive/MyDrive/data/python8.py\n",
            "Output of Read function is \n",
            "def get_ci ( p : float , r : float , t : float , n : float ) -> float :\n",
            "    return round ( p * ( ( 1 + ( r / ( n * 100 ) ) ) ** ( n * t)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-wNRDpxh4PB",
        "outputId": "056a5942-e6d5-48f6-910a-698e638038c4"
      },
      "source": [
        "convert_to_python(9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'function', 'to', 'find', 'rightmost', 'value', 'less', 'than', 'or', 'equal', 'to', 'x']\n",
            "trg = ['def', 'find_le', '(', 'a', ',', 'x', ')', ':', 'NEWLINE', 'INDENT', 'from', 'bisect', 'import', 'bisect_right', 'NEWLINE', 'i', '=', 'bisect_right', '(', 'a', ',', 'x', ')', 'NEWLINE', 'if', 'i', ':', 'NEWLINE', 'INDENT', 'return', 'a', '[', 'i', '-', '1', ']', 'NEWLINE', 'DEDENT', 'raise', 'ValueError', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'find_le', '(', 'a', ',', 'x', ')', ':', 'NEWLINE', 'INDENT', 'from', 'bisect', 'import', 'bisect_right', 'NEWLINE', 'i', '=', 'bisect_right', '(', 'a', ',', 'x', ')', 'NEWLINE', 'if', 'i', ':', 'NEWLINE', 'INDENT', 'return', 'a', '[', 'i', '-', '1', ']', 'NEWLINE', 'DEDENT', 'raise', 'ValueError', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python9.py\n",
            "Output of Read function is \n",
            "def find_le ( a , x ) :\n",
            "  from bisect import bisect_right\n",
            "i = bisect_right ( a , x )\n",
            "if i :\n",
            "    return a [ i - 1 ]\n",
            " raise ValueError\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpGa5QIoiBZC",
        "outputId": "fc65a581-ef91-4b08-b586-bbc533e39a11"
      },
      "source": [
        "convert_to_python(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'function', 'to', 'calculate', 'the', 'volume', 'v', 'of', 'ideal', 'gas', 'based', 'on', 'ideal', 'gas', 'equation', 'pressure', 'p', 'and', 'tempreature', 't', 'given']\n",
            "trg = ['def', 'find_volume_of_ideal_gas', '(', 'pressure', ':', 'float', ',', 'temp', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'r', '=', '8.3145', 'NEWLINE', 'return', '(', 'n', '*', 'r', '*', 'temp', ')', '/', 'pressure', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'find_volume_of_ideal_gas', '(', 'pressure', ':', 'float', ',', 'temp', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'r', '=', '8.3145', 'NEWLINE', 'return', '(', 'n', '*', 'r', '*', 'temp', ')', '/', 'pressure', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python10.py\n",
            "Output of Read function is \n",
            "def find_volume_of_ideal_gas ( pressure : float , temp : float , n : float ) -> float :\n",
            "  r = 8.3145\n",
            "  return ( n * r * temp ) / pressure\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybcXb3UJm27w"
      },
      "source": [
        "#### Generate python code for first 50 elements of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu1KBIWkj5jH",
        "outputId": "33987181-efd5-4f82-b3ef-059e0369b651"
      },
      "source": [
        "for i in range(50):\n",
        "  convert_to_python(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['define', 'a', 'function', 'that', 'can', 'accept', 'an', 'integer', 'number', 'as', 'input', 'and', 'print', 'the', 'it', 'is', 'an', 'even', 'number', 'if', 'the', 'number', 'is', 'even', 'otherwise', 'print', 'it', 'is', 'an', 'odd', 'number']\n",
            "trg = ['def', 'even_or_odd_num', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'if', 'n', '%', '2', '==', '0', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an even number\"', ')', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an odd number\"', ')', 'NEWLINE', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['def', 'even_or_odd_num', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'if', 'n', '%', '2', '==', '0', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an even number\"', ')', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"It is an odd number\"', ')', 'NEWLINE', 'DEDENT', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python0.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def even_or_odd_num ( n ) :\n",
            "  if n % 2 == 0 :\n",
            "  print ( \"It is an even number\" )\n",
            " else :\n",
            "  print ( \"It is an odd number\" )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'program', 'to', 'print', 'a', 'given', 'string', 'replacing', 'all', 'the', 'vowels', 'with']\n",
            "trg = ['st', '=', '\"Where is this going? Could you please help me understand!\"', 'NEWLINE', 'vowels', '=', '\"AEIOUaeiou\"', 'NEWLINE', 'for', 'v', 'in', 'vowels', ':', 'NEWLINE', 'INDENT', 'st', '=', 'st', '.', 'replace', '(', 'v', ',', \"'_'\", ')', 'NEWLINE', 'DEDENT', 'print', '(', 'st', ')', 'NEWLINE']\n",
            "predicted trg = ['st', '=', '\"Where is this going? Could you please help me understand!\"', 'NEWLINE', 'vowels', '=', '\"AEIOUaeiou\"', 'NEWLINE', 'for', 'v', 'in', 'vowels', ':', 'NEWLINE', 'INDENT', 'st', '=', 'st', '.', 'replace', '(', 'v', ',', \"'_'\", ')', 'NEWLINE', 'DEDENT', 'print', '(', 'st', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python1.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "st = \"Where is this going? Could you please help me understand!\"\n",
            "vowels = \"AEIOUaeiou\"\n",
            "for v in vowels :\n",
            "  st = st . replace ( v , '_' )\n",
            " print ( st )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'to', 'dict', 'to', 'zip', 'and', 'print', 'as', 'dictionary', 'elements', 'in', 'original', 'form']\n",
            "trg = ['a', '=', '{', '\"a\"', ':', '1', ',', '\"b\"', ':', '2', ',', '\"c\"', ':', '3', '}', 'NEWLINE', 'b', '=', 'dict', '(', 'zip', '(', 'a', '.', 'values', '(', ')', ',', 'a', '.', 'keys', '(', ')', ')', ')', 'NEWLINE', 'print', '(', 'b', ')', 'NEWLINE']\n",
            "predicted trg = ['a', '=', '{', '\"a\"', ':', '1', ',', '\"b\"', ':', '2', ',', '\"c\"', ':', '3', '}', 'NEWLINE', 'b', '=', 'dict', '(', 'zip', '(', 'a', '.', 'values', '(', ')', ',', 'a', '.', 'keys', '(', ')', ')', ')', 'NEWLINE', 'print', '(', 'b', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python2.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "a = { \"a\" : 1 , \"b\" : 2 , \"c\" : 3 }\n",
            "b = dict ( zip ( a . values ( ) , a . keys ( ) ) )\n",
            "print ( b )\n",
            "\n",
            "\n",
            "src = ['python', 'sigmoid', 'function']\n",
            "trg = ['def', 'sigmoid_activation', '(', 'l', ')', ':', 'NEWLINE', 'INDENT', 'return', '[', 'round', '(', '1', '/', '(', '1', '+', 'math', '.', 'exp', '(', '-', 'x', ')', ')', ',', '2', ')', 'for', 'x', 'in', 'l', ']', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'sigmoid_activation', '(', 'l', ')', ':', 'NEWLINE', 'INDENT', 'return', '[', 'round', '(', '1', '/', '(', '1', '+', 'math', '.', 'exp', '(', '-', 'x', ')', ')', ',', '2', ')', 'for', 'x', 'in', 'l', ']', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python3.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def sigmoid_activation ( l ) :\n",
            "    return [ round ( 1 / ( 1 + math . exp ( - x ) ) , 2 ) for x in l ]\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'which', 'takes', 'user', 'input', 'tuple', 'and', 'prints', 'length', 'of', 'each', 'tuple', 'element']\n",
            "trg = ['userInput', '=', 'input', '(', '\"Enter a tuple:\"', ')', 'NEWLINE', 'x', '=', 'map', '(', 'lambda', 'x', ':', 'len', '(', 'x', ')', ',', 'tuple', '(', 'x', '.', 'strip', '(', ')', 'for', 'x', 'in', 'userInput', '.', 'split', '(', \"','\", ')', ')', ')', 'NEWLINE', 'print', '(', 'list', '(', 'x', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['userInput', '=', 'input', '(', '\"Enter a tuple:\"', ')', 'NEWLINE', 'x', '=', 'map', '(', 'lambda', 'x', ':', 'len', '(', 'x', ')', ',', 'tuple', '(', 'x', '.', 'strip', '(', ')', 'for', 'x', 'in', 'userInput', '.', 'split', '(', \"','\", ')', ')', ')', 'NEWLINE', 'print', '(', 'list', '(', 'x', ')', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python4.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "userInput = input ( \"Enter a tuple:\" )\n",
            "x = map ( lambda x : len ( x ) , tuple ( x . strip ( ) for x in userInput . split ( ',' ) ) )\n",
            "print ( list ( x ) )\n",
            "\n",
            "\n",
            "src = ['class', 'to', 'show', 'implementation', 'of', 'static', 'method']\n",
            "trg = ['class', 'Mathematics', ':', 'NEWLINE', 'INDENT', 'def', '__init__', '(', 'self', ',', 'msg', '=', '\"Demo class of Mathematics\"', ')', ':', 'NEWLINE', 'INDENT', 'self', '.', 'msg', '=', 'msg', 'NEWLINE', 'DEDENT', 'def', '__str__', '(', 'self', ')', ':', 'NEWLINE', 'INDENT', 'return', \"f' String representation of an object'\", 'NEWLINE', 'DEDENT', 'def', '__repr__', '(', 'self', ')', ':', 'NEWLINE', 'INDENT', 'return', \"f' repr representation of an object with parameter {self.msg}'\", 'NEWLINE', 'DEDENT', '@', 'staticmethod', 'NEWLINE', 'def', 'addition', '(', 'a', ':', '\"Variable1\"', ',', 'b', ':', \"'Variable2'\", ')', ':', 'NEWLINE', 'INDENT', 'return', 'a', '+', 'b', 'NEWLINE', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['class', 'Mathematics', ':', 'NEWLINE', 'INDENT', 'def', '__init__', '(', 'self', ',', 'msg', '=', '\"Demo class of Mathematics\"', ')', ':', 'NEWLINE', 'INDENT', 'self', '.', 'msg', '=', 'msg', 'NEWLINE', 'DEDENT', 'def', '__str__', '(', 'self', ')', ':', 'NEWLINE', 'INDENT', 'return', \"f' String representation of an object'\", 'NEWLINE', 'DEDENT', 'def', '__repr__', '(', 'self', ')', ':', 'NEWLINE', 'INDENT', 'return', \"f' repr representation of an object with parameter {self.msg}'\", 'NEWLINE', 'DEDENT', '@', 'staticmethod']\n",
            "/content/gdrive/MyDrive/data/python5.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "class Mathematics :\n",
            "  def __init__ ( self , msg = \"Demo class of Mathematics\" ) :\n",
            "  self . msg = msg\n",
            " def __str__ ( self ) :\n",
            "    return f' String representation of an object'\n",
            " def __repr__ ( self ) :\n",
            "    return f' repr representation of an object with parameter {self.msg}'\n",
            "@\n",
            "\n",
            "src = ['write', 'a', 'python', 'function', 'that', 'takes', 'in', 'two', 'numbers', 'and', 'returns', 'their', 'hcf']\n",
            "trg = ['def', 'hcf', '(', 'num1', ',', 'num2', ')', ':', 'NEWLINE', 'INDENT', 'smaller', '=', 'num1', 'if', 'num1', '<', 'num2', 'else', 'num2', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', 'smaller', '+', '1', ')', ':', 'NEWLINE', 'INDENT', 'if', '(', 'num1', '%', 'i', '==', '0', ')', 'and', '(', 'num2', '%', 'i', '==', '0', ')', ':', 'NEWLINE', 'INDENT', 'hcf', '=', 'i', 'NEWLINE', 'DEDENT', 'DEDENT', 'return', 'hcf', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'hcf', '(', 'num1', ',', 'num2', ')', ':', 'NEWLINE', 'INDENT', 'smaller', '=', 'num1', 'if', 'num1', '<', 'num2', 'else', 'num2', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', 'smaller', '+', '1', ')', ':', 'NEWLINE', 'INDENT', 'if', '(', 'num1', '%', 'i', '==', '0', ')', 'and', '(', 'num2', '%', 'i', '==', '0', ')']\n",
            "/content/gdrive/MyDrive/data/python6.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def hcf ( num1 , num2 ) :\n",
            "  smaller = num1 if num1 < num2 else num2\n",
            "for i in range ( 1 , smaller + 1 ) :\n",
            "  if ( num1 % i == 0 ) and ( num2 % i ==0\n",
            "\n",
            "src = ['define', 'a', 'class', 'named', 'american', 'and', 'its', 'subclass', 'newyorker']\n",
            "trg = ['class', 'American', '(', 'object', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT', 'class', 'NewYorker', '(', 'American', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['class', 'American', '(', 'object', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT', 'class', 'NewYorker', '(', 'American', ')', ':', 'NEWLINE', 'INDENT', 'pass', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python7.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "class American ( object ) :\n",
            "  pass\n",
            " class NewYorker ( American ) :\n",
            "  pass\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'function', 'to', 'calculate', 'the', 'compound', 'interest', 'for', 'principal', 'p', 'rate', 'r', 'and', 'time', 'in', 'years', 'y']\n",
            "trg = ['def', 'get_ci', '(', 'p', ':', 'float', ',', 'r', ':', 'float', ',', 't', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'return', 'round', '(', 'p', '*', '(', '(', '1', '+', '(', 'r', '/', '(', 'n', '*', '100', ')', ')', ')', '**', '(', 'n', '*', 't', ')', ')', '-', 'p', ',', '2', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'get_ci', '(', 'p', ':', 'float', ',', 'r', ':', 'float', ',', 't', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'return', 'round', '(', 'p', '*', '(', '(', '1', '+', '(', 'r', '/', '(', 'n', '*', '100', ')', ')', ')', '**', '(', 'n', '*', 't', ')', '-']\n",
            "/content/gdrive/MyDrive/data/python8.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def get_ci ( p : float , r : float , t : float , n : float ) -> float :\n",
            "    return round ( p * ( ( 1 + ( r / ( n * 100 ) ) ) ** ( n * t)\n",
            "\n",
            "src = ['write', 'a', 'python', 'function', 'to', 'find', 'rightmost', 'value', 'less', 'than', 'or', 'equal', 'to', 'x']\n",
            "trg = ['def', 'find_le', '(', 'a', ',', 'x', ')', ':', 'NEWLINE', 'INDENT', 'from', 'bisect', 'import', 'bisect_right', 'NEWLINE', 'i', '=', 'bisect_right', '(', 'a', ',', 'x', ')', 'NEWLINE', 'if', 'i', ':', 'NEWLINE', 'INDENT', 'return', 'a', '[', 'i', '-', '1', ']', 'NEWLINE', 'DEDENT', 'raise', 'ValueError', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'find_le', '(', 'a', ',', 'x', ')', ':', 'NEWLINE', 'INDENT', 'from', 'bisect', 'import', 'bisect_right', 'NEWLINE', 'i', '=', 'bisect_right', '(', 'a', ',', 'x', ')', 'NEWLINE', 'if', 'i', ':', 'NEWLINE', 'INDENT', 'return', 'a', '[', 'i', '-', '1', ']', 'NEWLINE', 'DEDENT', 'raise', 'ValueError', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python9.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def find_le ( a , x ) :\n",
            "  from bisect import bisect_right\n",
            "i = bisect_right ( a , x )\n",
            "if i :\n",
            "    return a [ i - 1 ]\n",
            " raise ValueError\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'function', 'to', 'calculate', 'the', 'volume', 'v', 'of', 'ideal', 'gas', 'based', 'on', 'ideal', 'gas', 'equation', 'pressure', 'p', 'and', 'tempreature', 't', 'given']\n",
            "trg = ['def', 'find_volume_of_ideal_gas', '(', 'pressure', ':', 'float', ',', 'temp', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'r', '=', '8.3145', 'NEWLINE', 'return', '(', 'n', '*', 'r', '*', 'temp', ')', '/', 'pressure', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'find_volume_of_ideal_gas', '(', 'pressure', ':', 'float', ',', 'temp', ':', 'float', ',', 'n', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'r', '=', '8.3145', 'NEWLINE', 'return', '(', 'n', '*', 'r', '*', 'temp', ')', '/', 'pressure', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python10.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def find_volume_of_ideal_gas ( pressure : float , temp : float , n : float ) -> float :\n",
            "  r = 8.3145\n",
            "  return ( n * r * temp ) / pressure\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'to', 'demonstrate', 'working', 'of', 'words', 'frequency', 'in', 'string', 'shorthands']\n",
            "trg = ['test_str', '=', \"'Gfg is best . Geeks are good and Geeks like Gfg'\", 'NEWLINE', 'print', '(', '\"The original string is : \"', '+', 'str', '(', 'test_str', ')', ')', 'NEWLINE', 'res', '=', '{', 'key', ':', 'test_str', '.', 'count', '(', 'key', ')', 'for', 'key', 'in', 'test_str', '.', 'split', '(', ')', '}', 'NEWLINE', 'print', '(', '\"The words frequency : \"', '+', 'str', '(', 'res', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['test_str', '=', \"'Gfg is best . Geeks are good and Geeks like Gfg'\", 'NEWLINE', 'print', '(', '\"The original string is : \"', '+', 'str', '(', 'test_str', ')', ')', 'NEWLINE', 'res', '=', '{', 'key', ':', 'test_str', '.', 'count', '(', 'key', ')', 'for', 'key', 'in', 'test_str', '.', 'split', '(', ')', '}', 'NEWLINE', 'print', '(', '\"The words frequency : \"', '+', 'str', '(', 'res', ')', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python11.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "test_str = 'Gfg is best . Geeks are good and Geeks like Gfg'\n",
            "print ( \"The original string is : \" + str ( test_str ) )\n",
            "res = { key : test_str . count ( key ) for key in test_str . split ( ) }\n",
            "print ( \"The words frequency : \" + str ( res ) )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'function', 'that', 'returns', 'tan', 'value', 'of', 'the', 'input']\n",
            "trg = ['def', 'tan', '(', 'x', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'import', 'math', 'NEWLINE', 'return', 'math', '.', 'tan', '(', 'x', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'tan', '(', 'x', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'import', 'math', 'NEWLINE', 'return', 'math', '.', 'tan', '(', 'x', ')', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python12.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def tan ( x : float ) -> float :\n",
            "  import math\n",
            "  return math . tan ( x )\n",
            "\n",
            "\n",
            "src = ['calculate', 'memory', 'is', 'being', 'used', 'by', 'an', 'list', 'in', 'python']\n",
            "trg = ['import', 'sys', 'NEWLINE', 'list1', '=', '[', \"'Scott'\", ',', \"'Eric'\", ',', \"'Kelly'\", ',', \"'Emma'\", ',', \"'Smith'\", ']', 'NEWLINE', 'print', '(', '\"size of list = \"', ',', 'sys', '.', 'getsizeof', '(', 'list1', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['import', 'sys', 'NEWLINE', 'list1', '=', '[', \"'Scott'\", ',', \"'Eric'\", ',', \"'Kelly'\", ',', \"'Emma'\", ',', \"'Smith'\", ']', 'NEWLINE', 'print', '(', '\"size of list = \"', ',', 'sys', '.', 'getsizeof', '(', 'list1', ')', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python13.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "import sys\n",
            "list1 = [ 'Scott' , 'Eric' , 'Kelly' , 'Emma' , 'Smith' ]\n",
            "print ( \"size of list = \" , sys . getsizeof ( list1 ) )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'to', 'iterate', 'an', 'dict', 'and', 'concatenate']\n",
            "trg = ['D', '=', 'dict', '(', 'p', '=', \"'san'\", ',', 'q', '=', \"'foundry'\", ')', 'NEWLINE', 'print', '(', \"'{p}{q}'\", '.', 'format', '(', '**', 'D', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['D', '=', 'dict', '(', 'p', '=', \"'san'\", ',', 'q', '=', \"'foundry'\", ')', 'NEWLINE', 'print', '(', \"'{p}{q}'\", '.', 'format', '(', '**', 'D', ')', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python14.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "D = dict ( p = 'san' , q = 'foundry' )\n",
            "print ( '{p}{q}' . format ( ** D ) )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'function', 'to', 'calculate', 'the', 'gravitational', 'force', 'between', 'two', 'objects', 'of', 'mass', 'm1', 'and', 'm2', 'and', 'distance', 'of', 'r', 'between', 'them']\n",
            "trg = ['def', 'cal_gforce', '(', 'mass1', ':', 'float', ',', 'mass2', ':', 'float', ',', 'distance', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'g', '=', '6.674', '*', '(', '10', ')', '**', '(', '-', '11', ')', 'NEWLINE', 'return', '(', 'g', '*', 'mass1', '*', 'mass2', ')', '/', '(', 'distance', '**', '2', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'cal_gforce', '(', 'mass1', ':', 'float', ',', 'mass2', ':', 'float', ',', 'distance', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'g', '=', '6.674', '*', '(', '10', ')', '**', '(', '-', '11', ')', 'NEWLINE', 'return', '(', 'g', '*', 'mass1', '*', 'mass2', ')', '/', '(', 'distance', '**', '2', ')', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python15.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def cal_gforce ( mass1 : float , mass2 : float , distance : float ) -> float :\n",
            "  g = 6.674 * ( 10 ) ** ( - 11 )\n",
            "  return ( g * mass1 * mass2 ) / ( distance ** 2 )\n",
            "\n",
            "\n",
            "src = ['generate', 'a', 'random', 'ndimensional', 'array', 'of', 'float', 'numbers']\n",
            "trg = ['import', 'numpy', 'NEWLINE', 'random_float_array', '=', 'numpy', '.', 'random', '.', 'rand', '(', '2', ',', '2', ')', 'NEWLINE', 'print', '(', '\"2 X 2 random float array in [0.0, 1.0] \\\\n\"', ',', 'random_float_array', ',', '\"\\\\n\"', ')', 'NEWLINE']\n",
            "predicted trg = ['import', 'numpy', 'NEWLINE', 'random_float_array', '=', 'numpy', '.', 'random', '.', 'rand', '(', '2', ',', '2', ')', 'NEWLINE', 'print', '(', '\"2 X 2 random float array in [0.0, 1.0] \\\\n\"', ',', 'random_float_array', ',', '\"\\\\n\"', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python16.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "import numpy\n",
            "random_float_array = numpy . random . rand ( 2 , 2 )\n",
            "print ( \"2 X 2 random float array in [0.0, 1.0] \\n\" , random_float_array , \"\\n\" )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'to', 'multiply', 'three', 'numbers', 'and', 'print', 'the', 'result']\n",
            "trg = ['num1', '=', '2', 'NEWLINE', 'num2', '=', '4', 'NEWLINE', 'num3', '=', '6', 'NEWLINE', 'print', '(', 'num1', '*', 'num2', '*', 'num3', ')', 'NEWLINE']\n",
            "predicted trg = ['num1', '=', '2', 'NEWLINE', 'num2', '=', '4', 'NEWLINE', 'num3', '=', '6', 'NEWLINE', 'print', '(', 'num1', '*', 'num2', '*', 'num3', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python17.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "num1 = 2\n",
            "num2 = 4\n",
            "num3 = 6\n",
            "print ( num1 * num2 * num3 )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'to', 'find', 'the', 'sum', 'and', 'average', 'of', 'the', 'list', 'print', 'the', 'sum', 'and', 'average']\n",
            "trg = ['L', '=', '[', '4', ',', '5', ',', '1', ',', '2', ',', '9', ',', '7', ',', '10', ',', '8', ']', 'NEWLINE', 'count', '=', '0', 'NEWLINE', 'for', 'i', 'in', 'L', ':', 'NEWLINE', 'INDENT', 'count', '+=', 'i', 'NEWLINE', 'DEDENT', 'avg', '=', 'count', '/', 'len', '(', 'L', ')', 'NEWLINE', 'print', '(', '\"sum = \"', ',', 'count', ')', 'NEWLINE', 'print', '(', '\"average = \"', ',', 'avg', ')', 'NEWLINE']\n",
            "predicted trg = ['L', '=', '[', '4', ',', '5', ',', '1', ',', '2', ',', '9', ',', '7', ',', '10', ',', '8', ']', 'NEWLINE', 'count', '=', '0', 'NEWLINE', 'for', 'i', 'in', 'L', ':', 'NEWLINE', 'INDENT', 'count', '+=', 'i', 'NEWLINE', 'DEDENT', 'avg', '=', 'count', '/', 'len', '(', 'L', ')', 'NEWLINE', 'print', '(', '\"sum = \"', ',', 'count']\n",
            "/content/gdrive/MyDrive/data/python18.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "L = [ 4 , 5 , 1 , 2 , 9 , 7 , 10 , 8 ]\n",
            "count = 0\n",
            "for i in L :\n",
            "  count += i\n",
            " avg = count / len ( L )\n",
            "print ( \"sum = \",\n",
            "\n",
            "src = ['write', 'a', 'python', 'function', 'to', 'capitalizes', 'the', 'first', 'letter', 'of', 'each', 'word', 'in', 'a', 'string']\n",
            "trg = ['def', 'capitalize', '(', 'text', ')', ':', 'NEWLINE', 'INDENT', 'return', 'text', '.', 'title', '(', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'capitalize', '(', 'text', ')', ':', 'NEWLINE', 'INDENT', 'return', 'text', '.', 'title', '(', ')', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python19.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def capitalize ( text ) :\n",
            "    return text . title ( )\n",
            "\n",
            "\n",
            "src = ['7', 'add', 'a', 'value', 'to', 'the', 'start', 'of', 'a', 'list', 'python']\n",
            "trg = ['var', '=', '7', 'NEWLINE', 'array', '=', '[', '1', ',', '2', ',', '3', ',', '4', ',', '5', ',', '6', ']', 'NEWLINE', 'array', '.', 'insert', '(', '0', ',', 'var', ')', 'NEWLINE']\n",
            "predicted trg = ['var', '=', '7', 'NEWLINE', 'array', '=', '[', '1', ',', '2', ',', '3', ',', '4', ',', '5', ',', '6', ']', 'NEWLINE', 'array', '.', 'insert', '(', '0', ',', 'var', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python20.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "var = 7\n",
            "array = [ 1 , 2 , 3 , 4 , 5 , 6 ]\n",
            "array . insert ( 0 , var )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'that', 'converts', 'a', 'hexadecimal', 'number', 'to', 'hexadecimal', 'and', 'prints', 'it']\n",
            "trg = ['hexadecimal_num', '=', \"'FF'\", 'NEWLINE', 'decimal_num', '=', 'int', '(', 'hexadecimal_num', ',', '16', ')', 'NEWLINE', 'print', '(', 'decimal_num', ')', 'NEWLINE']\n",
            "predicted trg = ['hexadecimal_num', '=', \"'FF'\", 'NEWLINE', 'decimal_num', '=', 'int', '(', 'hexadecimal_num', ',', '16', ')', 'NEWLINE', 'print', '(', 'decimal_num', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python21.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "hexadecimal_num = 'FF'\n",
            "decimal_num = int ( hexadecimal_num , 16 )\n",
            "print ( decimal_num )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'function', 'to', 'converting', 'an', 'integer', 'to', 'a', 'string', 'in', 'any', 'base']\n",
            "trg = ['def', 'to_string', '(', 'n', ',', 'base', ')', ':', 'NEWLINE', 'INDENT', 'conver_tString', '=', '\"0123456789ABCDEF\"', 'NEWLINE', 'if', 'n', '<', 'base', ':', 'NEWLINE', 'INDENT', 'return', 'conver_tString', '[', 'n', ']', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'return', 'to_string', '(', 'n', '//', 'base', ',', 'base', ')', '+', 'conver_tString', '[', 'n', ']', '%', 'base', 'NEWLINE', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['def', 'to_string', '(', 'n', ',', 'base', ')', ':', 'NEWLINE', 'INDENT', 'conver_tString', '=', '\"0123456789ABCDEF\"', 'NEWLINE', 'if', 'n', '<', 'base', ':', 'NEWLINE', 'INDENT', 'return', 'conver_tString', '[', 'n', ']', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'return', 'to_string', '(', 'n', '//', 'base', ',', 'base', ')', '+', 'conver_tString', '[', 'n', ']', '%', 'base', 'NEWLINE', 'DEDENT']\n",
            "/content/gdrive/MyDrive/data/python22.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def to_string ( n , base ) :\n",
            "  conver_tString = \"0123456789ABCDEF\"\n",
            "if n < base :\n",
            "    return conver_tString [ n ]\n",
            " else :\n",
            "    return to_string ( n // base , base ) + conver_tString [ n ] % base\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'function', 'to', 'return', 'the', 'type', 'roots', 'of', 'a', 'quadratic', 'equation', 'ax2', 'bx', 'c', '0']\n",
            "trg = ['def', 'root_type', '(', 'a', ':', 'float', ',', 'b', ':', 'float', ',', 'c', ':', 'float', ')', ':', 'NEWLINE', 'INDENT', 'if', 'b', '**', '2', '-', '4', '*', 'a', '*', 'c', '>=', '0', ':', 'NEWLINE', 'INDENT', 'return', \"'real'\", 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'return', \"'imaginary'\", 'NEWLINE', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['def', 'root_type', '(', 'a', ':', 'float', ',', 'b', ':', 'float', ',', 'c', ':', 'float', ')', ':', 'NEWLINE', 'INDENT', 'if', 'b', '**', '2', '-', '4', '*', 'a', '*', 'c', '>=', '0', ':', 'NEWLINE', 'INDENT', 'return', \"'real'\", 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'return', \"'imaginary'\", 'NEWLINE', 'DEDENT', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python23.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def root_type ( a : float , b : float , c : float ) :\n",
            "  if b ** 2 - 4 * a * c >= 0 :\n",
            "    return 'real'\n",
            " else :\n",
            "    return 'imaginary'\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'program', 'to', 'find', 'the', 'difference', 'between', 'two', 'times']\n",
            "trg = ['def', 'difference', '(', 'h1', ',', 'm1', ',', 'h2', ',', 'm2', ')', ':', 'NEWLINE', 'INDENT', 't1', '=', 'h1', '*', '60', '+', 'm1', 'NEWLINE', 't2', '=', 'h2', '*', '60', '+', 'm2', 'NEWLINE', 'if', '(', 't1', '==', 't2', ')', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"Both are same times\"', ')', 'NEWLINE', 'return', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'diff', '=', 't2', '-', 't1', 'NEWLINE', 'DEDENT', 'h', '=', '(', 'int', '(', 'diff', '/', '60', ')', ')', '%', '24', 'NEWLINE', 'm', '=', 'diff', '%', '60', 'NEWLINE', 'print', '(', 'h', ',', '\":\"', ',', 'm', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'difference', '(', 'h1', ',', 'm1', ',', 'h2', ',', 'm2', ')', ':', 'NEWLINE', 'INDENT', 't1', '=', 'h1', '*', '60', '+', 'm1', 'NEWLINE', 't2', '=', 'h2', '*', '60', '+', 'm2', 'NEWLINE', 'if', '(', 't1', '==', 't2', ')', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"Both are same times\"', ')', 'NEWLINE', 'return', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE']\n",
            "/content/gdrive/MyDrive/data/python24.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def difference ( h1 , m1 , h2 , m2 ) :\n",
            "  t1 = h1 * 60 + m1\n",
            "t2 = h2 * 60 + m2\n",
            "if ( t1 == t2 ) :\n",
            "  print ( \"Both are same times\" )\n",
            "  return\n",
            " else:\n",
            "\n",
            "src = ['write', 'a', 'function', 'to', 'calculate', 'the', 'moment', 'of', 'inertia', 'of', 'a', 'ring', 'of', 'mass', 'm', 'and', 'radius', 'r']\n",
            "trg = ['def', 'cal_mi_ring', '(', 'mass', ':', 'float', ',', 'radius', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'return', 'mass', '*', '(', 'radius', '**', '2', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'cal_mi_ring', '(', 'mass', ':', 'float', ',', 'radius', ':', 'float', ')', '->', 'float', ':', 'NEWLINE', 'INDENT', 'return', 'mass', '*', '(', 'radius', '**', '2', ')', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python25.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def cal_mi_ring ( mass : float , radius : float ) -> float :\n",
            "    return mass * ( radius ** 2 )\n",
            "\n",
            "\n",
            "src = ['python', 'program', 'for', 'the', 'sum', 'of', 'first', 'n', 'numbers']\n",
            "trg = ['def', 'sum_n_num', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'return', 'n', '*', '(', 'n', '+', '1', ')', '/', '2', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'sum_n_num', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'return', 'n', '*', '(', 'n', '+', '1', ')', '/', '2', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python26.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def sum_n_num ( n ) :\n",
            "    return n * ( n + 1 ) / 2\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'to', 'compute', 'the', 'sum', 'of', 'all', 'the', 'multiples', 'of', '3', 'or', '5', 'below', '500']\n",
            "trg = ['n', '=', '0', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', '500', ')', ':', 'NEWLINE', 'INDENT', 'if', 'not', 'i', '%', '5', 'or', 'not', 'i', '%', '3', ':', 'NEWLINE', 'INDENT', 'n', '=', 'n', '+', 'i', 'NEWLINE', 'DEDENT', 'DEDENT', 'print', '(', 'n', ')', 'NEWLINE']\n",
            "predicted trg = ['n', '=', '0', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', '500', ')', ':', 'NEWLINE', 'INDENT', 'if', 'not', 'i', '%', '5', 'or', 'not', 'i', '%', '3', ':', 'NEWLINE', 'INDENT', 'n', '=', 'n', '+', 'i', 'NEWLINE', 'DEDENT', 'DEDENT', 'print', '(', 'n', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python27.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "n = 0\n",
            "for i in range ( 1 , 500 ) :\n",
            "  if not i % 5 or not i % 3 :\n",
            "  n = n + i\n",
            "  print ( n )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'that', 'takes', 'two', 'sets', 'as', 'input', 'and', 'print', 'the', 'common', 'elements']\n",
            "trg = ['s1', '=', 'eval', '(', 'input', '(', '\"Enter set 1 \"', ')', ')', 'NEWLINE', 's2', '=', 'eval', '(', 'input', '(', '\"Enter set 2 \"', ')', ')', 'NEWLINE', 'print', '(', 's1', '.', 'intersection', '(', 's2', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['s1', '=', 'eval', '(', 'input', '(', '\"Enter set 1 \"', ')', ')', 'NEWLINE', 's2', '=', 'eval', '(', 'input', '(', '\"Enter set 2 \"', ')', ')', 'NEWLINE', 'print', '(', 's1', '.', 'intersection', '(', 's2', ')', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python28.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "s1 = eval ( input ( \"Enter set 1 \" ) )\n",
            "s2 = eval ( input ( \"Enter set 2 \" ) )\n",
            "print ( s1 . intersection ( s2 ) )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'program', 'to', 'count', 'the', 'number', 'of', 'words', 'in', 'a', 'sentence']\n",
            "trg = ['test_string', '=', '\"This is a good book\"', 'NEWLINE', 'res', '=', 'len', '(', 'test_string', '.', 'split', '(', ')', ')', 'NEWLINE', 'print', '(', 'f\"The number of words in string are :{str(res)}\"', ')', 'NEWLINE']\n",
            "predicted trg = ['test_string', '=', '\"This is a good book\"', 'NEWLINE', 'res', '=', 'len', '(', 'test_string', '.', 'split', '(', ')', ')', 'NEWLINE', 'print', '(', 'f\"The number of words in string are :{str(res)}\"', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python29.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "test_string = \"This is a good book\"\n",
            "res = len ( test_string . split ( ) )\n",
            "print ( f\"The number of words in string are :{str(res)}\" )\n",
            "\n",
            "\n",
            "src = ['deepcopy', 'in', 'python']\n",
            "trg = ['list1', '=', '[', '[', '1', ']', ',', '[', '2', ']', ']', 'NEWLINE', 'list2', '=', 'list1', '.', 'copy', '(', ')', 'NEWLINE', 'list3', '=', 'deepcopy', '(', 'list1', ')', 'NEWLINE', 'print', '(', \"'IDs:\\\\nlist1: {}\\\\nlist2: {}\\\\nlist3: {}\\\\n'\", 'NEWLINE', '.', 'format', '(', 'id', '(', 'list1', ')', ',', 'id', '(', 'list2', ')', ',', 'id', '(', 'list3', ')', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['list1', '=', '[', '[', '1', ']', ',', '[', '2', ']', ']', 'NEWLINE', 'list2', '=', 'list1', '.', 'copy', '(', ')', 'NEWLINE', 'list3', '=', 'deepcopy', '(', 'list1', ')', 'NEWLINE', 'print', '(', \"'IDs:\\\\nlist1: {}\\\\nlist2: {}\\\\nlist3: {}\\\\n'\", 'NEWLINE', '.', 'format', '(', 'id', '(', 'list1', ')', ',', 'id', '(', 'list2', ')', ',', 'id', '(', 'list2', ')', ')', ')']\n",
            "/content/gdrive/MyDrive/data/python30.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "list1 = [ [ 1 ] , [ 2 ] ]\n",
            "list2 = list1 . copy ( )\n",
            "list3 = deepcopy ( list1 )\n",
            "print ( 'IDs:\\nlist1: {}\\nlist2: {}\\nlist3: {}\\n'\n",
            ". format ( id ( list1 ) , id ( list2 ) , id ( list2 ))\n",
            "\n",
            "src = ['write', 'a', 'python', 'function', 'to', 'count', 'the', 'number', 'of', 'words', 'in', 'a', 'text', 'file']\n",
            "trg = ['def', 'check_words', '(', ')', ':', 'NEWLINE', 'INDENT', 'fname', '=', 'input', '(', '\"file name: \"', ')', 'NEWLINE', 'num_words', '=', '0', 'NEWLINE', 'with', 'open', '(', 'fname', ',', \"'r'\", ')', 'as', 'f', ':', 'NEWLINE', 'INDENT', 'for', 'line', 'in', 'f', ':', 'NEWLINE', 'INDENT', 'words', '=', 'line', '.', 'split', '(', ')', 'NEWLINE', 'num_words', '+=', 'len', '(', 'words', ')', 'NEWLINE', 'DEDENT', 'DEDENT', 'print', '(', '\"Number of words = \"', ',', 'num_words', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'check_words', '(', ')', ':', 'NEWLINE', 'INDENT', 'fname', '=', 'input', '(', '\"file name: \"', ')', 'NEWLINE', 'num_words', '=', '0', 'NEWLINE', 'with', 'open', '(', 'fname', ',', \"'r'\", ')', 'as', 'f', ':', 'NEWLINE', 'INDENT', 'for', 'line', 'in', 'f', ':', 'NEWLINE', 'INDENT', 'words', '=', 'line', '.', 'split', '(', ')', 'NEWLINE', 'num_words', '+=', 'len', '(', 'words']\n",
            "/content/gdrive/MyDrive/data/python31.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def check_words ( ) :\n",
            "  fname = input ( \"file name: \" )\n",
            "num_words = 0\n",
            "with open ( fname , 'r' ) as f :\n",
            "  for line in f :\n",
            "  words = line . split ( )\n",
            "num_words += len(\n",
            "\n",
            "src = ['python', 'funcction', 'to', 'find', 'the', 'factors', 'of', 'a', 'number']\n",
            "trg = ['def', 'print_factors', '(', 'x', ')', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"The factors of\"', ',', 'x', ',', '\"are:\"', ')', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', 'x', '+', '1', ')', ':', 'NEWLINE', 'INDENT', 'if', 'x', '%', 'i', '==', '0', ':', 'NEWLINE', 'INDENT', 'print', '(', 'i', ')', 'NEWLINE', 'DEDENT', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['def', 'print_factors', '(', 'x', ')', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"The factors of\"', ',', 'x', ',', '\"are:\"', ')', 'NEWLINE', 'for', 'i', 'in', 'range', '(', '1', ',', 'x', '+', '1', ')', ':', 'NEWLINE', 'INDENT', 'if', 'x', '%', 'i', '==', '0', ':', 'NEWLINE', 'INDENT', 'print', '(', 'i', ')', 'NEWLINE', 'DEDENT', 'DEDENT', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python32.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def print_factors ( x ) :\n",
            "  print ( \"The factors of\" , x , \"are:\" )\n",
            "for i in range ( 1 , x + 1 ) :\n",
            "  if x % i == 0 :\n",
            "  print ( i )\n",
            " \n",
            "\n",
            "src = ['write', 'python3', 'code', 'to', 'demonstrate', 'working', 'of', 'add', 'list', 'elements', 'to', 'tuples', 'list', 'using', 'list', 'comprehension', 'operator']\n",
            "trg = ['test_list', '=', '[', '(', '5', ',', '6', ')', ',', '(', '2', ',', '4', ')', ',', '(', '5', ',', '7', ')', ',', '(', '2', ',', '5', ')', ']', 'NEWLINE', 'print', '(', '\"The original list is : \"', '+', 'str', '(', 'test_list', ')', ')', 'NEWLINE', 'sub_list', '=', '[', '7', ',', '2', ',', '4', ',', '6', ']', 'NEWLINE', 'res', '=', '[', '(', '*', 'sub', ',', '*', 'sub_list', ')', 'for', 'sub', 'in', 'test_list', ']', 'NEWLINE', 'print', '(', '\"The modified list : \"', '+', 'str', '(', 'res', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['test_list', '=', '[', '(', '5', ',', '6', ')', ',', '(', '2', ',', '4', ')', ',', '(', '5', ',', '7', ')', ',', '(', '2', ',', '5', ')', ']', 'NEWLINE', 'print', '(', '\"The original list is : \"', '+', 'str', '(', 'test_list', ')', ')', 'NEWLINE', 'sub_list', '=', '[', '7', ',', '2', ',', '4', ',', '6', ']', 'NEWLINE']\n",
            "/content/gdrive/MyDrive/data/python33.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "test_list = [ ( 5 , 6 ) , ( 2 , 4 ) , ( 5 , 7 ) , ( 2 , 5 ) ]\n",
            "print ( \"The original list is : \" + str ( test_list ) )\n",
            "sub_list = [ 7 , 2 , 4 , 6]\n",
            "\n",
            "src = ['python', 'parse', 'datetime', 'from', 'string']\n",
            "trg = ['from', 'datetime', 'import', 'datetime', 'NEWLINE', 'datetime_object', '=', 'datetime', '.', 'strptime', '(', \"'Jun 1 2005  1:33PM'\", ',', \"'%b %d %Y %I:%M%p'\", ')', 'NEWLINE']\n",
            "predicted trg = ['from', 'datetime', 'import', 'datetime', 'NEWLINE', 'datetime_object', '=', 'datetime', '.', 'strptime', '(', \"'Jun 1 2005  1:33PM'\", ',', \"'%b %d %Y %I:%M%p'\", ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python34.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "from datetime import datetime\n",
            "datetime_object = datetime . strptime ( 'Jun 1 2005  1:33PM' , '%b %d %Y %I:%M%p' )\n",
            "\n",
            "\n",
            "src = ['2', 'write', 'a', 'python', 'function', 'to', 'split', 'a', 'string', 'at', 'space']\n",
            "trg = ['def', 'string_split_at_space', '(', 'string', ')', ':', 'NEWLINE', 'INDENT', 'return', 'string', '.', 'split', '(', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'string_split_at_space', '(', 'string', ')', ':', 'NEWLINE', 'INDENT', 'return', 'string', '.', 'split', '(', ')', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python35.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def string_split_at_space ( string ) :\n",
            "    return string . split ( )\n",
            "\n",
            "\n",
            "src = ['python', 'program', 'to', 'remove', 'leading', 'characters']\n",
            "trg = ['word', '=', '\" xyz \"', 'NEWLINE', 'lstrip', '=', 'word', '.', 'lstrip', '(', ')', 'NEWLINE', 'print', '(', 'f\"String ater removal of leading characters:{lstrip}\"', ')', 'NEWLINE']\n",
            "predicted trg = ['word', '=', '\" xyz \"', 'NEWLINE', 'lstrip', '=', 'word', '.', 'lstrip', '(', ')', 'NEWLINE', 'print', '(', 'f\"String ater removal of leading characters:{lstrip}\"', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python36.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "word = \" xyz \"\n",
            "lstrip = word . lstrip ( )\n",
            "print ( f\"String ater removal of leading characters:{lstrip}\" )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'program', 'to', 'return', 'the', 'absolute', 'value', 'in', 'python']\n",
            "trg = ['def', 'get_absolute_value', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'if', 'n', '>=', '0', ':', 'NEWLINE', 'INDENT', 'return', 'n', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'return', '-', 'n', 'NEWLINE', 'DEDENT', 'DEDENT', 'print', '(', 'get_absolute_value', '(', '101', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['num', '=', '-', '10', 'NEWLINE', 'print', '(', \"f'Absolute of {num} is {abs(num)}'\", ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python37.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "num = - 10\n",
            "print ( f'Absolute of {num} is {abs(num)}' )\n",
            "\n",
            "\n",
            "src = ['reverse', 'a', 'given', 'string']\n",
            "trg = ['str1', '=', '\"PYnative\"', 'NEWLINE', 'print', '(', '\"Original String is:\"', ',', 'str1', ')', 'NEWLINE', 'str1', '=', 'str1', '[', ':', ':', '-', '1', ']', 'NEWLINE', 'print', '(', '\"Reversed String is:\"', ',', 'str1', ')', 'NEWLINE']\n",
            "predicted trg = ['str1', '=', '\"PYnative\"', 'NEWLINE', 'print', '(', '\"Original String is:\"', ',', 'str1', ')', 'NEWLINE', 'str1', '=', 'str1', '[', ':', ':', '-', '1', ']', 'NEWLINE', 'print', '(', '\"Reversed String is:\"', ',', 'str1', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python38.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "str1 = \"PYnative\"\n",
            "print ( \"Original String is:\" , str1 )\n",
            "str1 = str1 [ : : - 1 ]\n",
            "print ( \"Reversed String is:\" , str1 )\n",
            "\n",
            "\n",
            "src = ['define', 'a', 'function', 'that', 'can', 'accept', 'two', 'strings', 'as', 'input', 'and', 'print', 'the', 'string', 'with', 'maximum', 'length', 'in', 'console', 'if', 'two', 'strings', 'have', 'the', 'same', 'length', 'then', 'the', 'function', 'should', 'print', 'al', 'l', 'strings', 'line', 'by', 'line']\n",
            "trg = ['def', 'max_len_str', '(', 's1', ',', 's2', ')', ':', 'NEWLINE', 'INDENT', 'len1', '=', 'len', '(', 's1', ')', 'NEWLINE', 'len2', '=', 'len', '(', 's2', ')', 'NEWLINE', 'if', 'len1', '>', 'len2', ':', 'NEWLINE', 'INDENT', 'print', '(', 's1', ')', 'NEWLINE', 'DEDENT', 'elif', 'len2', '>', 'len1', ':', 'NEWLINE', 'INDENT', 'print', '(', 's2', ')', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'print', '(', 's1', ')', 'NEWLINE', 'print', '(', 's2', ')', 'NEWLINE', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['def', 'max_len_str', '(', 's1', ',', 's2', ')', ':', 'NEWLINE', 'INDENT', 'len1', '=', 'len', '(', 's1', ')', 'NEWLINE', 'len2', '=', 'len', '(', 's2', ')', 'NEWLINE', 'if', 'len1', '>', 'len2', ':', 'NEWLINE', 'INDENT', 'print', '(', 's1', ')', 'NEWLINE', 'DEDENT', 'elif', 'len2', '>', 'len1', ':', 'NEWLINE', 'INDENT', 'print', '(', 's2', ')', 'NEWLINE', 'DEDENT']\n",
            "/content/gdrive/MyDrive/data/python39.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def max_len_str ( s1 , s2 ) :\n",
            "  len1 = len ( s1 )\n",
            "len2 = len ( s2 )\n",
            "if len1 > len2 :\n",
            "  print ( s1 )\n",
            " elif len2 > len1 :\n",
            "  print ( s2 )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'function', 'that', 'returns', 'list', 'of', 'elements', 'with', 'n', 'power', 'to', 'elements', 'of', 'list']\n",
            "trg = ['def', 'n_power', '(', 'l1', ':', 'list', ',', 'power', ':', 'int', ')', '->', 'list', ':', 'NEWLINE', 'INDENT', 'return', '[', 'i', '**', 'power', 'for', 'i', 'in', 'l1', ']', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'n_power', '(', 'l1', ':', 'list', ',', 'power', ':', 'int', ')', '->', 'list', ':', 'NEWLINE', 'INDENT', 'return', '[', 'i', '**', 'power', 'for', 'i', 'in', 'l1', ']', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python40.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def n_power ( l1 : list , power : int ) -> list :\n",
            "    return [ i ** power for i in l1 ]\n",
            "\n",
            "\n",
            "src = ['python', 'program', 'to', 'raise', 'a', 'runtimeerror', 'exception']\n",
            "trg = ['raise', 'RuntimeError', '(', \"'something wrong'\", ')', 'NEWLINE']\n",
            "predicted trg = ['raise', 'RuntimeError', '(', \"'something wrong'\", ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python41.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "raise RuntimeError ( 'something wrong' )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'program', 'to', 'find', 'and', 'print', 'the', 'largest', 'among', 'three', 'number']\n",
            "trg = ['snum1', '=', '10', 'NEWLINE', 'num2', '=', '12', 'NEWLINE', 'num3', '=', '14', 'NEWLINE', 'if', '(', 'num1', '>=', 'num2', ')', 'and', '(', 'num1', '>=', 'num3', ')', ':', 'NEWLINE', 'INDENT', 'largest', '=', 'num1', 'NEWLINE', 'DEDENT', 'elif', '(', 'num2', '>=', 'num1', ')', 'and', '(', 'num2', '>=', 'num3', ')', ':', 'NEWLINE', 'INDENT', 'largest', '=', 'num2', 'NEWLINE', 'DEDENT', 'else', ':', 'largest', '=', 'num3', 'NEWLINE', 'print', '(', \"f'largest:{largest}'\", ')', 'NEWLINE']\n",
            "predicted trg = ['num1', '=', '10', 'NEWLINE', 'num2', '=', '14', 'NEWLINE', 'num3', '=', '12', 'NEWLINE', 'if', '(', 'num1', '>=', 'num2', ')', 'and', '(', 'num1', '>=', 'num3', ')', ':', 'NEWLINE', 'INDENT', 'largest', '=', 'num1', 'NEWLINE', 'DEDENT', 'elif', '(', 'num2', '>=', 'num1', ')', 'and', '(', 'num2', '>=', 'num3', ')', ':', 'NEWLINE', 'INDENT', 'largest', '=', 'num2']\n",
            "/content/gdrive/MyDrive/data/python42.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "num1 = 10\n",
            "num2 = 14\n",
            "num3 = 12\n",
            "if ( num1 >= num2 ) and ( num1 >= num3 ) :\n",
            "  largest = num1\n",
            " elif ( num2 >= num1 ) and ( num2 >= num3 ) :\n",
            "  largest=\n",
            "\n",
            "src = ['python', 'function', 'for', 'finding', 'the', 'derivative', 'of', 'tangent', 'angle']\n",
            "trg = ['def', 'dtangent', '(', 'angle', ')', ':', 'NEWLINE', 'INDENT', '\"\"\" returns the tangent value for an angle mentioned in radians\"\"\"', 'NEWLINE', 'return', '1', '/', '(', 'math', '.', 'cos', '(', 'angle', ')', '**', '2', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'dtangent', '(', 'angle', ')', ':', 'NEWLINE', 'INDENT', '\"\"\" returns the tangent value for an angle mentioned in radians\"\"\"', 'NEWLINE', 'return', '1', '/', '(', 'math', '.', 'cos', '(', 'angle', ')', '**', '2', ')', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python43.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def dtangent ( angle ) :\n",
            "  \"\"\" returns the tangent value for an angle mentioned in radians\"\"\"\n",
            "  return 1 / ( math . cos ( angle ) ** 2 )\n",
            "\n",
            "\n",
            "src = ['write', 'python', 'code', 'to', 'demonstrate', 'to', 'remove', 'the', 'tuples', 'if', 'certain', 'criteria', 'met']\n",
            "trg = ['ini_tuple', '=', '[', '(', \"'b'\", ',', '100', ')', ',', '(', \"'c'\", ',', '200', ')', ',', '(', \"'c'\", ',', '45', ')', ',', 'NEWLINE', '(', \"'d'\", ',', '876', ')', ',', '(', \"'e'\", ',', '75', ')', ']', 'NEWLINE', 'print', '(', '\"intial_list\"', ',', 'str', '(', 'ini_tuple', ')', ')', 'NEWLINE', 'result', '=', '[', ']', 'NEWLINE', 'for', 'i', 'in', 'ini_tuple', ':', 'NEWLINE', 'INDENT', 'if', 'i', '[', '1', ']', '<=', '100', ':', 'NEWLINE', 'INDENT', 'result', '.', 'append', '(', 'i', ')', 'NEWLINE', 'DEDENT', 'DEDENT', 'print', '(', '\"Resultant tuple list: \"', ',', 'str', '(', 'result', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['ini_tuple', '=', '[', '(', \"'b'\", ',', '100', ')', ',', '(', \"'c'\", ',', '200', ')', ',', '(', \"'c'\", ',', '45', ')', ',', 'NEWLINE', '(', \"'d'\", ',', '876', ')', ',', '(', \"'e'\", ',', '75', ')', ']', 'NEWLINE', 'print', '(', '\"intial_list\"', ',', 'str', '(', 'ini_tuple', ')', ')', 'NEWLINE', 'result', '=', '[', ']', 'NEWLINE']\n",
            "/content/gdrive/MyDrive/data/python44.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "ini_tuple = [ ( 'b' , 100 ) , ( 'c' , 200 ) , ( 'c' , 45 ) ,\n",
            "( 'd' , 876 ) , ( 'e' , 75 ) ]\n",
            "print ( \"intial_list\" , str ( ini_tuple ) )\n",
            "result = []\n",
            "\n",
            "src = ['write', 'a', 'function', 'to', 'check', 'if', 'a', 'lower', 'case', 'letter', 'exists', 'in', 'a', 'given', 'string']\n",
            "trg = ['def', 'check_lower', '(', 'str1', ')', ':', 'NEWLINE', 'INDENT', 'for', 'char', 'in', 'str1', ':', 'NEWLINE', 'INDENT', 'k', '=', 'char', '.', 'islower', '(', ')', 'NEWLINE', 'if', 'k', '==', 'True', ':', 'NEWLINE', 'INDENT', 'return', 'True', 'NEWLINE', 'DEDENT', 'DEDENT', 'if', '(', 'k', '!=', '1', ')', ':', 'NEWLINE', 'INDENT', 'return', 'False', 'NEWLINE', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['def', 'check_lower', '(', 'str1', ')', ':', 'NEWLINE', 'INDENT', 'for', 'char', 'in', 'str1', ':', 'NEWLINE', 'INDENT', 'k', '=', 'char', '.', 'islower', '(', ')', 'NEWLINE', 'if', 'k', '==', 'True', ':', 'NEWLINE', 'INDENT', 'return', 'True', 'NEWLINE', 'DEDENT', 'DEDENT', 'if', '(', 'k', '!=', '1', ')', ':', 'NEWLINE', 'INDENT', 'return', 'False', 'NEWLINE', 'DEDENT', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python45.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def check_lower ( str1 ) :\n",
            "  for char in str1 :\n",
            "  k = char . islower ( )\n",
            "if k == True :\n",
            "    return True\n",
            "  if ( k != 1 ) :\n",
            "    return False\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'python', 'function', 'to', 'return', 'the', 'number', 'of', 'whitespace', 'separated', 'tokens']\n",
            "trg = ['def', 'tokenise', '(', 'string', ')', ':', 'NEWLINE', 'INDENT', 'return', 'len', '(', 'string', '.', 'split', '(', ')', ')', 'NEWLINE', 'DEDENT']\n",
            "predicted trg = ['def', 'tokenise', '(', 'string', ')', ':', 'NEWLINE', 'INDENT', 'return', 'len', '(', 'string', '.', 'split', '(', ')', ')', 'NEWLINE', 'DEDENT', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python46.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def tokenise ( string ) :\n",
            "    return len ( string . split ( ) )\n",
            "\n",
            "\n",
            "src = ['python', 'program', 'to', 'display', 'fibonacci', 'sequence', 'using', 'recursion']\n",
            "trg = ['def', 'recur_fibo', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'if', 'n', '<=', '1', ':', 'NEWLINE', 'INDENT', 'return', 'n', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'return', '(', 'recur_fibo', '(', 'n', '-', '1', ')', '+', 'recur_fibo', '(', 'n', '-', '2', ')', ')', 'NEWLINE', 'DEDENT', 'DEDENT', 'nterms', '=', '10', 'NEWLINE', 'if', 'nterms', '<=', '0', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"Plese enter a positive integer\"', ')', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'print', '(', '\"Fibonacci sequence:\"', ')', 'NEWLINE', 'for', 'i', 'in', 'range', '(', 'nterms', ')', ':', 'NEWLINE', 'INDENT', 'print', '(', 'recur_fibo', '(', 'i', ')', ')', 'NEWLINE', 'DEDENT', 'DEDENT']\n",
            "predicted trg = ['def', 'recur_fibo', '(', 'n', ')', ':', 'NEWLINE', 'INDENT', 'if', 'n', '<=', '1', ':', 'NEWLINE', 'INDENT', 'return', 'n', 'NEWLINE', 'DEDENT', 'else', ':', 'NEWLINE', 'INDENT', 'return', '(', 'recur_fibo', '(', 'n', '-', '1', ')', '+', 'recur_fibo', '(', 'n', '-', '2', ')', ')', 'NEWLINE', 'DEDENT', 'DEDENT', 'nterms', '=', '10', 'NEWLINE', 'if', 'nterms', '<=', '0']\n",
            "/content/gdrive/MyDrive/data/python47.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "def recur_fibo ( n ) :\n",
            "  if n <= 1 :\n",
            "    return n\n",
            " else :\n",
            "    return ( recur_fibo ( n - 1 ) + recur_fibo ( n - 2 ) )\n",
            "  nterms = 10\n",
            "if nterms<=\n",
            "\n",
            "src = ['split', 'strings']\n",
            "trg = ['word', '=', '\"Hello World\"', 'NEWLINE', 'ksplit', '=', 'word', '.', 'split', '(', \"' '\", ')', 'NEWLINE', 'print', '(', 'f\"Splited Strings: {ksplit}\"', ')', 'NEWLINE']\n",
            "predicted trg = ['word', '=', '\"Hello World\"', 'NEWLINE', 'ksplit', '=', 'word', '.', 'split', '(', \"' '\", ')', 'NEWLINE', 'print', '(', 'f\"Splited Strings: {ksplit}\"', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python48.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "word = \"Hello World\"\n",
            "ksplit = word . split ( ' ' )\n",
            "print ( f\"Splited Strings: {ksplit}\" )\n",
            "\n",
            "\n",
            "src = ['write', 'a', 'program', 'to', 'increment', 'number', 'which', 'is', 'at', 'end', 'of', 'string']\n",
            "trg = ['import', 're', 'NEWLINE', 'str1', '=', \"'count001'\", 'NEWLINE', 'res', '=', 're', '.', 'sub', '(', \"r'[0-9]+$'\", ',', 'NEWLINE', 'lambda', 'x', ':', 'f\"{str(int(x.group())+1).zfill(len(x.group()))}\"', ',', 'NEWLINE', 'str1', ')', 'NEWLINE', 'print', '(', '\"Incremented numeric String : \"', '+', 'str', '(', 'res', ')', ')', 'NEWLINE']\n",
            "predicted trg = ['import', 're', 'NEWLINE', 'str1', '=', \"'count001'\", 'NEWLINE', 'res', '=', 're', '.', 'sub', '(', \"r'[0-9]+$'\", ',', 'NEWLINE', 'lambda', 'x', ':', 'f\"{str(int(x.group())+1).zfill(len(x.group()))}\"', ',', 'str1', ')', 'NEWLINE', 'print', '(', '\"Incremented numeric String : \"', '+', 'str', '(', 'res', ')', ')', 'NEWLINE', '<eos>']\n",
            "/content/gdrive/MyDrive/data/python49.py\n",
            "Output of Read function is \n",
            " \n",
            "==================================================\n",
            "import re\n",
            "str1 = 'count001'\n",
            "res = re . sub ( r'[0-9]+$' ,\n",
            "lambda x : f\"{str(int(x.group())+1).zfill(len(x.group()))}\" , str1 )\n",
            "print ( \"Incremented numeric String : \" + str ( res ) )\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9C0ih97sSrP"
      },
      "source": [
        "###  9.Execute Python Code through Interpreter\n",
        "The above python code generated is stored as \"python1.py\",\"python2.py\",\"python3.py\".The same has to be validated to check whether the code can be executed.\n",
        "\n",
        "**25 such programs are selected and executed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfZz7-XH68Ey"
      },
      "source": [
        "#### Python 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSU7H9PTt2dX"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python2.py' ."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ESj6GFVCM2B",
        "outputId": "7bc01d38-2dfd-452f-a542-a1c832168b0d"
      },
      "source": [
        "import python2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k44699c97G3J"
      },
      "source": [
        "#### Python 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovx8vZNTw-8p"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python4.py' ."
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYwJRhTGtTUP",
        "outputId": "cc8c21dd-b8ec-41fe-fc1f-da9164eea0c2"
      },
      "source": [
        "import python4"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a tuple:(1,2)\n",
            "[2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnEBjJui7bsr"
      },
      "source": [
        "#### Python 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dNNbzzr0U2i"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python11.py' ."
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PVJjzye0gO3",
        "outputId": "94e88082-082e-42a6-e05b-606a0f3bfc60"
      },
      "source": [
        "import python11"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The original string is : Gfg is best . Geeks are good and Geeks like Gfg\n",
            "The words frequency : {'Gfg': 2, 'is': 1, 'best': 1, '.': 1, 'Geeks': 2, 'are': 1, 'good': 1, 'and': 1, 'like': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbltQQDN7hgr"
      },
      "source": [
        "#### Python 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEQn2U9j1edB"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python13.py' ."
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEY018Sa1viE",
        "outputId": "ab521eaf-c8a2-4d1e-d5b1-ebf05cce8618"
      },
      "source": [
        "import python13"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of list =  112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCDxdWrS7kh1"
      },
      "source": [
        "#### Python 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV3404uK10oq"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python14.py' .\n"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g28CxSiH2HC5",
        "outputId": "53de7f8c-a4fc-400c-98df-b97e3009c51e"
      },
      "source": [
        "import python14"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sanfoundry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkDj3JTT7nzl"
      },
      "source": [
        "#### Python 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k99GG40d2KjF"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python15.py' ."
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW_tiVMP2RfR",
        "outputId": "11e43cd1-a675-4e5e-ffda-f5789a90ed74"
      },
      "source": [
        "import python15\n",
        "python15.cal_gforce(1.2,1.3,2.4)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8075416666666664e-11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z83UYzj87tho"
      },
      "source": [
        "#### Python 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dswtX8Sg3Bwa"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python16.py' ."
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ItpqrTc3Lp0",
        "outputId": "c9aedbab-1699-4e26-fa6e-c6351970e26a"
      },
      "source": [
        "import python16"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 X 2 random float array in [0.0, 1.0] \n",
            " [[0.48420933 0.16791637]\n",
            " [0.81881357 0.7461074 ]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEuh5-Dz7xPe"
      },
      "source": [
        "#### Python 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgfTQ9DT3TNH"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python17.py' ."
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSRwb9w031Ll",
        "outputId": "59b08821-c136-47fc-b72e-2198240b64e9"
      },
      "source": [
        "import python17"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l98g_-1I77Bz"
      },
      "source": [
        "#### Python 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udhZwPMc338s"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python19.py' ."
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV9aI76K7_zR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SfIf8S8R4EOl",
        "outputId": "b69c5212-d548-4cbc-d3a9-96807686b5cd"
      },
      "source": [
        "import python19\n",
        "python19.capitalize('goodmorning')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Goodmorning'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKkAzBIy7-XN"
      },
      "source": [
        "#### Python 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq00XGIF4O3S"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python21.py' ."
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFrrABfk4VL5",
        "outputId": "7f3a6345-4769-4741-fcb3-b69ba4cbb019"
      },
      "source": [
        "import python21"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20GqS6dT8DRL"
      },
      "source": [
        "#### Python 11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-evpm8Vj4pw1"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python25.py' ."
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecp1Dsry42u4",
        "outputId": "8ea6cb41-7d91-4096-ba89-0cc7d1c63fef"
      },
      "source": [
        "import python25\n",
        "python25.cal_mi_ring(2.5,3.5)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCh-DMrW8GYC"
      },
      "source": [
        "#### Python 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uirJAs5j5fJg"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python26.py' ."
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjlLEXyY5mLc",
        "outputId": "677fe61e-10fc-4b0c-80c8-784c7f65a703"
      },
      "source": [
        "import python26\n",
        "python26.sum_n_num(4)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDejmD6B8Jou"
      },
      "source": [
        "#### Python 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCQ31h8y5wJ0"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python28.py' ."
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wAmI-7s56Cm",
        "outputId": "7c590ba6-6315-42d6-b5e4-4eb746c83e9e"
      },
      "source": [
        "import python28"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter set 1 {1,2,3}\n",
            "Enter set 2 {3,4,5}\n",
            "{3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP76ybua8NDe"
      },
      "source": [
        "#### Python 14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTajb7hD6YC6"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python29.py' ."
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_QC22Rn6lkW",
        "outputId": "e36e8442-775a-4dcb-b118-cc4b0489feef"
      },
      "source": [
        "import python29"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of words in string are :5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OyFa5a68y6z"
      },
      "source": [
        "#### Python 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9PThGQ76ql_"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python33.py' ."
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjpK80SH8vEB",
        "outputId": "c2700af0-7e2b-4ef1-e17a-d5577a03c4f5"
      },
      "source": [
        "import python33"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The original list is : [(5, 6), (2, 4), (5, 7), (2, 5)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3VcTMig8_T8"
      },
      "source": [
        "#### Python 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fAgMhjM86Bj"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python35.py' ."
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CNNQTlu9Izl",
        "outputId": "1a845ad4-144f-47eb-8d18-2f28eba06046"
      },
      "source": [
        "import python35\n",
        "python35.string_split_at_space(\"abc cde gee\")"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abc', 'cde', 'gee']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Lmq3iv9d6X"
      },
      "source": [
        "#### Python 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOUWJIxU9hpj"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python36.py' ."
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYO8-jjO9nel",
        "outputId": "035a1956-fe87-4cde-8096-16d0c60b3887"
      },
      "source": [
        "import python36"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "String ater removal of leading characters:xyz \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifOqMntv9usU"
      },
      "source": [
        "#### Python 18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSPaTCjp9tpV"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python37.py' ."
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3-bqNR6-Ap-",
        "outputId": "50b61c8e-4d1d-4f84-e55f-80a916ce629e"
      },
      "source": [
        "import python37"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Absolute of -10 is 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDgF_XNK-EVN"
      },
      "source": [
        "#### Python 19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUabHYKv-OLu"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python38.py' ."
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq3HUgZS-Z2d",
        "outputId": "296a0165-71c7-4faa-d48b-dc7195802368"
      },
      "source": [
        "import python38"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original String is: PYnative\n",
            "Reversed String is: evitanYP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrowQblO-oAw"
      },
      "source": [
        "#### Python 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeUBCIKQ-gBx"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python40.py' ."
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d59qjoB8-wQQ",
        "outputId": "eefaa8d6-7704-4c7d-aad3-72d5f0e83ef7"
      },
      "source": [
        "import python40\n",
        "python40.n_power([1,2,3],4)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 16, 81]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLkLzCIK-c3b"
      },
      "source": [
        "#### Python 21"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPs-N4ve_EOd"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python41.py' ."
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Wekbkqfe_KJ1",
        "outputId": "a4048926-aa89-4d7b-f468-6ca47da421ef"
      },
      "source": [
        "import python41"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-23617ee8e74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpython41\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/python41.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m'something wrong'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: something wrong"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHSsFTGw_Wq5"
      },
      "source": [
        "#### Python *22*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q6Kp2Fi_q0U"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python44.py' ."
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aBYWcRV_vZe",
        "outputId": "3631672d-5c74-4560-b8e3-54dedecca804"
      },
      "source": [
        "import python44"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intial_list [('b', 100), ('c', 200), ('c', 45), ('d', 876), ('e', 75)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv2JPRNGAYry"
      },
      "source": [
        "#### Python 23"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udOigNcZAghJ"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python46.py' ."
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrxoXVZCAo6C",
        "outputId": "c615721f-62fa-40de-ef93-c84135e1ee56"
      },
      "source": [
        "import python46\n",
        "python46.tokenise(\"Hello how are you\")"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wemvI1e2BIZv"
      },
      "source": [
        "#### Python 24"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2qsyN7nBMCF"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python48.py' ."
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqeyOY-lBVEu",
        "outputId": "15e0ec83-80f3-4f02-9c11-881863f54345"
      },
      "source": [
        "import python48"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splited Strings: ['Hello', 'World']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH2WNAlOBaVc"
      },
      "source": [
        "#### Python 25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRPK8iB1BiCC"
      },
      "source": [
        "!cp -rf '/content/gdrive/MyDrive/data/python49.py' ."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap02N1OSBw5w",
        "outputId": "09c4e6ef-a6c1-4a37-bbbf-c8779b7f6146"
      },
      "source": [
        "import python49"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Incremented numeric String : count002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY7SsC8TEzFn"
      },
      "source": [
        "Just looking at the test loss, we get better performance. This is a pretty good sign that this model architecture is doing something right! Relieving the information compression seems like the way forard, and in the next tutorial we'll expand on this even further with *attention*."
      ]
    }
  ]
}